{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44ca522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading regex-2025.11.3-cp311-cp311-macosx_11_0_arm64.whl (288 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, hf-xet, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.20.0 fsspec-2025.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 regex-2025.11.3 safetensors-0.6.2 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.1\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp311-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from torch) (2025.10.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.9.1-cp311-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [torch]32m3/4\u001b[0m [torch]kx]\n",
      "\u001b[1A\u001b[2KSuccessfully installed mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.9.1\n"
     ]
    }
   ],
   "source": [
    "# Install the core library for Transformers\n",
    "!pip install transformers\n",
    "\n",
    "# Install PyTorch or TensorFlow (the backend framework)\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad5053d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 126 reviews from '../Reviews/Anytime Fitness MacPherson Mall_reviews.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sentiment scoring using model: cardiffnlp/twitter-roberta-base-sentiment...\n",
      "\n",
      "--- Scoring Complete ---\n",
      "Sentiment data added and saved to 'Sentiment_scores_Anytime Fitness MacPherson Mall.csv'.\n",
      "\n",
      "First 5 rows of the resulting data:\n",
      "                            outlet                 author  rating  \\\n",
      "0  Anytime Fitness MacPherson Mall                  Sarah       5   \n",
      "1  Anytime Fitness MacPherson Mall              Ney Rinda       5   \n",
      "2  Anytime Fitness MacPherson Mall        WIN WAR WAR SOE       5   \n",
      "3  Anytime Fitness MacPherson Mall  Zames from Repair.‌sg       5   \n",
      "4  Anytime Fitness MacPherson Mall             Reuben Goh       5   \n",
      "\n",
      "                                                text     date_posted  \\\n",
      "0  My friend and I signed up at this gym a few mo...  Date not found   \n",
      "1  I’ve been working out at Anytime Fitness MacPh...  Date not found   \n",
      "2  Anytime Fitness (MacPherson Mall) is a really ...  Date not found   \n",
      "3  an amazing gym with a clean and super well-mai...  Date not found   \n",
      "4  The gym was very well equipped with many new m...  Date not found   \n",
      "\n",
      "  BERT_Label  BERT_Score  \n",
      "0    LABEL_2    0.984812  \n",
      "1    LABEL_2    0.987702  \n",
      "2    LABEL_2    0.991006  \n",
      "3    LABEL_2    0.989761  \n",
      "4    LABEL_2    0.975181  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# --- Configuration ---\n",
    "# 1. Update this to the actual path of your CSV file\n",
    "input_file_path = \"../Reviews/Anytime Fitness MacPherson Mall_reviews.csv\" \n",
    "# 2. The column containing the review text\n",
    "text_column_name = \"text\" \n",
    "# 3. The name of the pre-trained BERT/RoBERTa model\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\" \n",
    "# 4. The name for the output file\n",
    "output_file_name = \"Sentiment_scores_Anytime Fitness MacPherson Mall.csv\" \n",
    "# 5. Batch size for processing (higher is faster, but uses more memory)\n",
    "batch_size = 32\n",
    "\n",
    "# --- Step 1: Read the Data ---\n",
    "try:\n",
    "    df = pd.read_csv(input_file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {input_file_path}. Please check the path.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Successfully loaded {len(df)} reviews from '{input_file_path}'.\")\n",
    "\n",
    "# --- Step 2: Load the Sentiment Pipeline ---\n",
    "# This downloads the model and tokenizer from the Hugging Face Hub\n",
    "try:\n",
    "    sentiment_pipeline = pipeline(\n",
    "        \"sentiment-analysis\", \n",
    "        model=model_name, \n",
    "        tokenizer=model_name\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the sentiment pipeline. Ensure 'transformers' and 'torch' are installed.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 3: Extract and Score the Text ---\n",
    "print(f\"Starting sentiment scoring using model: {model_name}...\")\n",
    "\n",
    "# Extract the list of text for the model\n",
    "reviews_to_score = df[text_column_name].tolist()\n",
    "\n",
    "# Run the scoring (using batching is more efficient for large files)\n",
    "results = sentiment_pipeline(reviews_to_score, batch_size=batch_size)\n",
    "\n",
    "# --- Step 4: Add Results to DataFrame ---\n",
    "\n",
    "# Extract the label (e.g., POSITIVE, NEGATIVE, NEUTRAL) and score (0 to 1)\n",
    "df['BERT_Label'] = [res['label'] for res in results]\n",
    "df['BERT_Score'] = [res['score'] for res in results]\n",
    "\n",
    "# --- Step 5: Save the Processed File ---\n",
    "df.to_csv(output_file_name, index=False)\n",
    "\n",
    "print(\"\\n--- Scoring Complete ---\")\n",
    "print(f\"Sentiment data added and saved to '{output_file_name}'.\")\n",
    "print(\"\\nFirst 5 rows of the resulting data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d764fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import pipeline\n",
    "\n",
    "# --- Configuration ---\n",
    "# 1. Update this to the actual path of the folder containing your 5 outlet CSVs\n",
    "# For demonstration, we'll use a simulated file list.\n",
    "REVIEWS_DIR = \"../Reviews\" \n",
    "TEXT_COLUMN_NAME = \"text\" \n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment\" \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# List of files/outlets you want to process (e.g., your top 5)\n",
    "# In a real script, you would use:\n",
    "# csv_files = [f for f in os.listdir(REVIEWS_DIR) if f.endswith('.csv')]\n",
    "csv_files = ['Anytime Fitness MacPherson Mall_reviews.csv', \n",
    "            'Outlet_B2.csv', \n",
    "            'Outlet_C3.csv', \n",
    "            'Outlet_D4.csv', \n",
    "            'Outlet_E5.csv']\n",
    "\n",
    "\n",
    "# --- Step 1: Define the BERT Sentiment Scoring Function ---\n",
    "def score_reviews_with_bert(df, sentiment_pipeline):\n",
    "    \"\"\"Applies the BERT sentiment pipeline to the DataFrame's text column.\"\"\"\n",
    "    if df.empty:\n",
    "        return None\n",
    "        \n",
    "    reviews_to_score = df[TEXT_COLUMN_NAME].tolist()\n",
    "    \n",
    "    # Process text in batches\n",
    "    results = sentiment_pipeline(reviews_to_score, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # Extract results\n",
    "    df['BERT_Label'] = [res['label'] for res in results]\n",
    "    df['BERT_Score'] = [res['score'] for res in results]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# --- Step 2: Load Pipeline (Run once) ---\n",
    "print(f\"Loading BERT pipeline: {MODEL_NAME}...\")\n",
    "try:\n",
    "    # This downloads the model and tokenizer\n",
    "    sentiment_pipeline = pipeline(\n",
    "        \"sentiment-analysis\", \n",
    "        model=MODEL_NAME, \n",
    "        tokenizer=MODEL_NAME\n",
    "    )\n",
    "    print(\"Pipeline loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load the sentiment pipeline. Ensure 'transformers' and 'torch' are installed. {e}\")\n",
    "    # We will simulate data from here if the pipeline fails to load\n",
    "    sentiment_pipeline = None\n",
    "\n",
    "\n",
    "# --- Step 3: Loop, Score, and Aggregate ---\n",
    "\n",
    "all_outlet_summaries = []\n",
    "\n",
    "# --- Step 4: Final Aggregation and Display ---\n",
    "\n",
    "final_summary_df = pd.DataFrame(all_outlet_summaries)\n",
    "\n",
    "# Sort by the Net Sentiment Score to easily identify best/worst\n",
    "final_summary_df = final_summary_df.sort_values(by='Net_Sentiment_Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✅ Aggregated Outlet Sentiment Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(final_summary_df)\n",
    "\n",
    "# Optional: Save the summary to a CSV file\n",
    "# final_summary_df.to_csv(\"top_5_outlet_sentiment_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is434_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
