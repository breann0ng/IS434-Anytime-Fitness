{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af48a31",
   "metadata": {},
   "source": [
    "## TOP 5 OUTLETS\n",
    "#### top_5_outlets.csv\n",
    "1. Anytime Fitness MacPherson Mall (5/5)- 126 Reviews\n",
    "2. Anytime Fitness City Square Mall (4.9/5)- 1051 Ratings\n",
    "3. Anytime Fitness Bedok 85 (4.9/5)- 1047 Ratings, _ Reviews\n",
    "4. Anytime Fitness Bukit Timah Central (4.9/5)- 960 Reviews\n",
    "5. Anytime Fitness Buona Vista (4.9/5)- 837 Reviews\n",
    "\n",
    "## BOTTOM 5 OUTLETS\n",
    "#### bottom_5_outlets.csv\n",
    "141. Anytime Fitness Paya Lebar (3.7/5)- 139 Reviews\n",
    "142. Anytime Fitness Upper Cross Street (3.5/5)- 142 Reviews\n",
    "143. Anytime Fitness hillV2 (3.2/5)- 112 Reviews\n",
    "144. Anytime Fitness NEX (3.1/5)- 303 Reviews\n",
    "145. Anytime Fitness Northpoint City (3/5)- 242 Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0949084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (4.38.0)\n",
      "Requirement already satisfied: webdriver-manager in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from trio<1.0,>=0.31.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from trio<1.0,>=0.31.0->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: requests in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from webdriver-manager) (2.32.5)\n",
      "Requirement already satisfied: python-dotenv in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from webdriver-manager) (1.2.1)\n",
      "Requirement already satisfied: packaging in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from webdriver-manager) (25.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from requests->webdriver-manager) (3.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5cf24",
   "metadata": {},
   "source": [
    "### REVIEW EXTRACTION: (1) MACPHERSON MALL\n",
    "#### 126 Ratings & Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7653ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§­ Testing scrape for: Anytime Fitness MacPherson Mall\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJX41bNAAX2jER8L9rlgPDC7E\n",
      "âœ… Chrome WebDriver initialized successfully.\n",
      "\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 3: Found 40 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 4: Found 60 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 5: Found 60 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 6: Found 52 new reviews (Total: 152)\n",
      "â³ No new reviews found. Waiting... (1/5)\n",
      "â³ No new reviews found. Waiting... (3/5)\n",
      "â³ No new reviews found. Waiting... (5/5)\n",
      "âœ‹ Reached end of reviews.\n",
      "\n",
      "âœ… Saved 126 unique reviews to 'Reviews/Anytime Fitness MacPherson Mall_reviews.csv'\n",
      "ðŸ“„ Found 0 reviews that were ratings only (no text).\n",
      "ðŸ“ˆ Review breakdown by rating:\n",
      "rating\n",
      "5    125\n",
      "1      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ==============================\n",
    "# LOAD OUTLET DATA\n",
    "# ==============================\n",
    "df_outlets = pd.read_csv(\"top_5_outlets.csv\")  # columns: name, maps_url\n",
    "\n",
    "# Pick top outlet\n",
    "df_top1 = df_outlets.head(1)\n",
    "outlet_name = df_top1.iloc[0][\"name\"]\n",
    "outlet_url = df_top1.iloc[0][\"maps_url\"]\n",
    "\n",
    "print(f\"ðŸ§­ Testing scrape for: {outlet_name}\")\n",
    "print(f\"ðŸ”— URL: {outlet_url}\")\n",
    "\n",
    "# ==============================\n",
    "# SETUP CHROME DRIVER\n",
    "# ==============================\n",
    "options = ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"--lang=en-US\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "# options.add_argument(\"--headless\")  # uncomment to run in background\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "wait = WebDriverWait(driver, 15)\n",
    "actions = ActionChains(driver)\n",
    "print(\"âœ… Chrome WebDriver initialized successfully.\")\n",
    "\n",
    "# ==============================\n",
    "# OPEN OUTLET PAGE AND CLICK REVIEWS\n",
    "# ==============================\n",
    "driver.get(outlet_url)\n",
    "time.sleep(3)\n",
    "\n",
    "# Click the \"Reviews\" button\n",
    "reviews_button = wait.until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label, \"Reviews for\")]'))\n",
    ")\n",
    "reviews_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# ==============================\n",
    "# SCROLL AND SCRAPE REVIEWS\n",
    "# ==============================\n",
    "# Find the scrollable container - this is the key fix\n",
    "scrollable_div = wait.until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]'))\n",
    ")\n",
    "\n",
    "all_reviews_data = []\n",
    "seen_review_ids = set()\n",
    "no_text_rating_count = 0\n",
    "\n",
    "scroll_pause = 1.5  # Slightly faster\n",
    "no_new_count = 0\n",
    "max_no_new = 5  # Increased patience\n",
    "previous_height = 0\n",
    "\n",
    "print(\"\\nðŸ”„ Starting to scroll and collect reviews...\")\n",
    "\n",
    "scroll_iteration = 0\n",
    "while True:\n",
    "    scroll_iteration += 1\n",
    "    \n",
    "    # Get current scroll height\n",
    "    current_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # Find all reviews currently loaded\n",
    "    review_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "    new_reviews = [r for r in review_elements if r.get_attribute(\"data-review-id\") not in seen_review_ids]\n",
    "\n",
    "    if new_reviews:\n",
    "        no_new_count = 0\n",
    "        print(f\"ðŸ“Š Iteration {scroll_iteration}: Found {len(new_reviews)} new reviews (Total: {len(seen_review_ids) + len(new_reviews)})\")\n",
    "    else:\n",
    "        no_new_count += 1\n",
    "        print(f\"â³ No new reviews found. Waiting... ({no_new_count}/{max_no_new})\")\n",
    "        if no_new_count >= max_no_new:\n",
    "            print(\"âœ‹ Reached end of reviews.\")\n",
    "            break\n",
    "\n",
    "    for r in new_reviews:\n",
    "        review_id = r.get_attribute(\"data-review-id\")\n",
    "        \n",
    "        # Skip if already processed\n",
    "        if review_id in seen_review_ids:\n",
    "            continue\n",
    "            \n",
    "        seen_review_ids.add(review_id)\n",
    "        \n",
    "        try:\n",
    "            # Expand truncated review text (\"More\" button)\n",
    "            try:\n",
    "                more_button = r.find_element(By.CLASS_NAME, 'w8nwRe')\n",
    "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(0.15)\n",
    "            except (NoSuchElementException, StaleElementReferenceException):\n",
    "                pass\n",
    "\n",
    "            # Extract review data\n",
    "            author_name = r.find_element(By.CLASS_NAME, 'd4r55').text\n",
    "            \n",
    "            # Check if this is an owner response (no rating element)\n",
    "            rating_elements = r.find_elements(By.CLASS_NAME, 'kvMYJc')\n",
    "            if not rating_elements:\n",
    "                continue  # Skip owner responses\n",
    "            \n",
    "            rating_element = rating_elements[0]\n",
    "            rating_text = rating_element.get_attribute('aria-label')\n",
    "            star_rating = int(rating_text.split(' ')[0])\n",
    "\n",
    "            # Extract review text (will be empty string if no text is present)\n",
    "            review_text = r.find_element(By.CLASS_NAME, 'wiI7pd').text.strip()\n",
    "\n",
    "            if not review_text:\n",
    "                no_text_rating_count += 1\n",
    "\n",
    "            try:\n",
    "                date_element = r.find_element(By.CLASS_NAME, 'rsqApe')\n",
    "                posting_date = date_element.text\n",
    "            except NoSuchElementException:\n",
    "                posting_date = \"Date not found\"\n",
    "\n",
    "            all_reviews_data.append({\n",
    "                \"outlet\": outlet_name,\n",
    "                \"author\": author_name,\n",
    "                \"rating\": star_rating,\n",
    "                \"text\": review_text,\n",
    "                \"date_posted\": posting_date\n",
    "            })\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # Scroll down smoothly - KEY FIX: Multiple small scrolls\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\n",
    "            \"arguments[0].scrollBy(0, arguments[0].scrollHeight / 3);\", \n",
    "            scrollable_div\n",
    "        )\n",
    "        time.sleep(0.3)\n",
    "    \n",
    "    # Additional wait for lazy loading\n",
    "    time.sleep(scroll_pause)\n",
    "    \n",
    "    # Check if we've actually scrolled\n",
    "    new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    if new_height == previous_height and len(new_reviews) == 0:\n",
    "        no_new_count += 1\n",
    "    previous_height = new_height\n",
    "\n",
    "# ==============================\n",
    "# SAVE RESULTS\n",
    "# ==============================\n",
    "driver.quit()\n",
    "\n",
    "if all_reviews_data:\n",
    "    os.makedirs(\"Reviews/Best\", exist_ok=True)\n",
    "    output_filename = os.path.join(\"Reviews/Best\", f\"{outlet_name}_reviews.csv\")\n",
    "    df_reviews = pd.DataFrame(all_reviews_data)\n",
    "    \n",
    "    # Remove duplicates based on author + text combination\n",
    "    initial_count = len(df_reviews)\n",
    "    df_reviews = df_reviews.drop_duplicates(subset=['author', 'text'], keep='first')\n",
    "    final_count = len(df_reviews)\n",
    "    \n",
    "    if initial_count > final_count:\n",
    "        print(f\"âš ï¸  Removed {initial_count - final_count} duplicate reviews\")\n",
    "    \n",
    "    df_reviews.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nâœ… Saved {final_count} unique reviews to '{output_filename}'\")\n",
    "    print(f\"ðŸ“„ Found {no_text_rating_count} reviews that were ratings only (no text).\")\n",
    "    print(f\"ðŸ“ˆ Review breakdown by rating:\")\n",
    "    print(df_reviews['rating'].value_counts().sort_index(ascending=False))\n",
    "else:\n",
    "    print(\"âŒ No reviews were scraped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1fbfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§­ Testing: Anytime Fitness MacPherson Mall\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJX41bNAAX2jER8L9rlgPDC7E\n",
      "\n",
      "============================================================\n",
      "METHOD 1: Testing Different XPath Selectors\n",
      "============================================================\n",
      "\n",
      "âœ“ Main role div\n",
      "  Found: 1 element(s)\n",
      "  scrollHeight: 652px\n",
      "  clientHeight: 652px\n",
      "  overflow-y: visible\n",
      "  â†’ Scrollable: NO âœ—\n",
      "\n",
      "âœ“ m6QErb class\n",
      "  Found: 10 element(s)\n",
      "  scrollHeight: 0px\n",
      "  clientHeight: 0px\n",
      "  overflow-y: visible\n",
      "  â†’ Scrollable: NO âœ—\n",
      "\n",
      "âœ“ DxyBCb class\n",
      "  Found: 1 element(s)\n",
      "  scrollHeight: 7070px\n",
      "  clientHeight: 603px\n",
      "  overflow-y: auto\n",
      "  â†’ Scrollable: YES âœ“\n",
      "\n",
      "âœ“ Both m6QErb and DxyBCb\n",
      "  Found: 1 element(s)\n",
      "  scrollHeight: 7070px\n",
      "  clientHeight: 603px\n",
      "  overflow-y: auto\n",
      "  â†’ Scrollable: YES âœ“\n",
      "\n",
      "âœ— Overflow styled ancestor\n",
      "  Found: 0 elements\n",
      "\n",
      "============================================================\n",
      "METHOD 2: Visual Highlighting Test\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¨ Highlighting potential scrollable containers...\n",
      "   (Watch your browser window!)\n",
      "\n",
      "âœ“ Red border applied to the detected scrollable container\n",
      "  â†’ Check your browser to see if it's around the reviews panel\n",
      "\n",
      "============================================================\n",
      "METHOD 3: Actual Scroll Test\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Reviews visible before scroll: 20\n",
      "ðŸ”„ Scrolling down...\n",
      "ðŸ“Š Reviews visible after scroll: 40\n",
      "âœ“ SUCCESS! Loaded 20 new reviews\n",
      "\n",
      "ðŸ”„ Scrolling again...\n",
      "ðŸ“Š Reviews after 2nd scroll: 60\n",
      "âœ“ SUCCESS! Loaded 20 more reviews\n",
      "\n",
      "============================================================\n",
      "METHOD 4: Find ALL Scrollable Divs\n",
      "============================================================\n",
      "\n",
      "Found 1 scrollable divs on page:\n",
      "\n",
      "  [219] m6QErb DxyBCb kA9KIf dS8AEf XiKgde \n",
      "      scrollHeight: 16086px, clientHeight: 594px\n",
      "\n",
      "\n",
      "============================================================\n",
      "âœ‹ Browser will stay open for 10 seconds for inspection\n",
      "   Press Ctrl+C to close immediately\n",
      "============================================================\n",
      "\n",
      "âœ… Test complete!\n"
     ]
    }
   ],
   "source": [
    "# Checking that the scrollable container is correctly identified (map reviews side panel)\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ==============================\n",
    "# LOAD OUTLET DATA\n",
    "# ==============================\n",
    "df_outlets = pd.read_csv(\"top_5_outlets.csv\")\n",
    "df_top1 = df_outlets.head(1)\n",
    "outlet_name = df_top1.iloc[0][\"name\"]\n",
    "outlet_url = df_top1.iloc[0][\"maps_url\"]\n",
    "\n",
    "print(f\"ðŸ§­ Testing: {outlet_name}\")\n",
    "print(f\"ðŸ”— URL: {outlet_url}\\n\")\n",
    "\n",
    "# ==============================\n",
    "# SETUP CHROME DRIVER\n",
    "# ==============================\n",
    "options = ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"--lang=en-US\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ==============================\n",
    "# OPEN PAGE AND CLICK REVIEWS\n",
    "# ==============================\n",
    "driver.get(outlet_url)\n",
    "time.sleep(3)\n",
    "\n",
    "reviews_button = wait.until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label, \"Reviews for\")]'))\n",
    ")\n",
    "reviews_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# ==============================\n",
    "# METHOD 1: TEST MULTIPLE XPATHS\n",
    "# ==============================\n",
    "print(\"=\" * 60)\n",
    "print(\"METHOD 1: Testing Different XPath Selectors\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "xpaths_to_test = [\n",
    "    ('//div[@role=\"main\"]', \"Main role div\"),\n",
    "    ('//div[contains(@class, \"m6QErb\")]', \"m6QErb class\"),\n",
    "    ('//div[contains(@class, \"DxyBCb\")]', \"DxyBCb class\"),\n",
    "    ('//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]', \"Both m6QErb and DxyBCb\"),\n",
    "    ('//div[@data-review-id]//ancestor::div[contains(@style, \"overflow\")]', \"Overflow styled ancestor\"),\n",
    "]\n",
    "\n",
    "for xpath, description in xpaths_to_test:\n",
    "    try:\n",
    "        elements = driver.find_elements(By.XPATH, xpath)\n",
    "        if elements:\n",
    "            elem = elements[0]\n",
    "            # Check scrollability properties\n",
    "            scroll_height = driver.execute_script(\"return arguments[0].scrollHeight\", elem)\n",
    "            client_height = driver.execute_script(\"return arguments[0].clientHeight\", elem)\n",
    "            overflow_y = driver.execute_script(\"return window.getComputedStyle(arguments[0]).overflowY\", elem)\n",
    "            \n",
    "            is_scrollable = scroll_height > client_height and overflow_y in ['scroll', 'auto']\n",
    "            \n",
    "            print(f\"\\nâœ“ {description}\")\n",
    "            print(f\"  Found: {len(elements)} element(s)\")\n",
    "            print(f\"  scrollHeight: {scroll_height}px\")\n",
    "            print(f\"  clientHeight: {client_height}px\")\n",
    "            print(f\"  overflow-y: {overflow_y}\")\n",
    "            print(f\"  â†’ Scrollable: {'YES âœ“' if is_scrollable else 'NO âœ—'}\")\n",
    "        else:\n",
    "            print(f\"\\nâœ— {description}\")\n",
    "            print(f\"  Found: 0 elements\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— {description}\")\n",
    "        print(f\"  Error: {str(e)[:100]}\")\n",
    "\n",
    "# ==============================\n",
    "# METHOD 2: VISUAL TEST WITH HIGHLIGHTING\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"METHOD 2: Visual Highlighting Test\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nðŸŽ¨ Highlighting potential scrollable containers...\")\n",
    "print(\"   (Watch your browser window!)\\n\")\n",
    "\n",
    "# Try to find and highlight the container\n",
    "try:\n",
    "    scrollable_div = driver.find_element(By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]')\n",
    "    \n",
    "    # Highlight it with a red border\n",
    "    driver.execute_script(\"\"\"\n",
    "        arguments[0].style.border = '5px solid red';\n",
    "        arguments[0].style.backgroundColor = 'rgba(255, 0, 0, 0.1)';\n",
    "    \"\"\", scrollable_div)\n",
    "    \n",
    "    print(\"âœ“ Red border applied to the detected scrollable container\")\n",
    "    print(\"  â†’ Check your browser to see if it's around the reviews panel\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Could not highlight: {e}\")\n",
    "\n",
    "# ==============================\n",
    "# METHOD 3: SCROLL TEST\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"METHOD 3: Actual Scroll Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    scrollable_div = driver.find_element(By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]')\n",
    "    \n",
    "    # Count reviews before scroll\n",
    "    reviews_before = len(driver.find_elements(By.XPATH, '//div[@data-review-id]'))\n",
    "    print(f\"\\nðŸ“Š Reviews visible before scroll: {reviews_before}\")\n",
    "    \n",
    "    # Scroll down\n",
    "    print(\"ðŸ”„ Scrolling down...\")\n",
    "    driver.execute_script(\"arguments[0].scrollTo(0, arguments[0].scrollHeight);\", scrollable_div)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Count reviews after scroll\n",
    "    reviews_after = len(driver.find_elements(By.XPATH, '//div[@data-review-id]'))\n",
    "    print(f\"ðŸ“Š Reviews visible after scroll: {reviews_after}\")\n",
    "    \n",
    "    if reviews_after > reviews_before:\n",
    "        print(f\"âœ“ SUCCESS! Loaded {reviews_after - reviews_before} new reviews\")\n",
    "    else:\n",
    "        print(\"âœ— WARNING: No new reviews loaded - might be wrong container or already at end\")\n",
    "    \n",
    "    # Try one more scroll\n",
    "    print(\"\\nðŸ”„ Scrolling again...\")\n",
    "    driver.execute_script(\"arguments[0].scrollTo(0, arguments[0].scrollHeight);\", scrollable_div)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    reviews_after_2 = len(driver.find_elements(By.XPATH, '//div[@data-review-id]'))\n",
    "    print(f\"ðŸ“Š Reviews after 2nd scroll: {reviews_after_2}\")\n",
    "    \n",
    "    if reviews_after_2 > reviews_after:\n",
    "        print(f\"âœ“ SUCCESS! Loaded {reviews_after_2 - reviews_after} more reviews\")\n",
    "    else:\n",
    "        print(\"â†’ No more reviews loaded (might have reached the end)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Scroll test failed: {e}\")\n",
    "\n",
    "# ==============================\n",
    "# METHOD 4: INSPECT ALL SCROLLABLE DIVS\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"METHOD 4: Find ALL Scrollable Divs\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_divs = driver.find_elements(By.TAG_NAME, \"div\")\n",
    "scrollable_divs = []\n",
    "\n",
    "for i, div in enumerate(all_divs):\n",
    "    try:\n",
    "        scroll_height = driver.execute_script(\"return arguments[0].scrollHeight\", div)\n",
    "        client_height = driver.execute_script(\"return arguments[0].clientHeight\", div)\n",
    "        overflow_y = driver.execute_script(\"return window.getComputedStyle(arguments[0]).overflowY\", div)\n",
    "        \n",
    "        if scroll_height > client_height and overflow_y in ['scroll', 'auto']:\n",
    "            class_name = div.get_attribute(\"class\") or \"no-class\"\n",
    "            scrollable_divs.append({\n",
    "                'index': i,\n",
    "                'classes': class_name[:80],  # Truncate long class names\n",
    "                'scrollHeight': scroll_height,\n",
    "                'clientHeight': client_height\n",
    "            })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"\\nFound {len(scrollable_divs)} scrollable divs on page:\\n\")\n",
    "for div_info in scrollable_divs[:10]:  # Show first 10\n",
    "    print(f\"  [{div_info['index']}] {div_info['classes']}\")\n",
    "    print(f\"      scrollHeight: {div_info['scrollHeight']}px, clientHeight: {div_info['clientHeight']}px\\n\")\n",
    "\n",
    "if len(scrollable_divs) > 10:\n",
    "    print(f\"  ... and {len(scrollable_divs) - 10} more\")\n",
    "\n",
    "# ==============================\n",
    "# KEEP BROWSER OPEN\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ‹ Browser will stay open for 10 seconds for inspection\")\n",
    "print(\"   Press Ctrl+C to close immediately\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    time.sleep(10)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nðŸ‘‹ Closing browser...\")\n",
    "\n",
    "driver.quit()\n",
    "print(\"\\nâœ… Test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5892ef",
   "metadata": {},
   "source": [
    "### REVIEW EXTRACTION: (1) MACPHERSON MALL\n",
    "<span style=\"font-size: 15pt; font-weight: bold;\">1051 Ratings, 900 Reviews</span> \n",
    "\n",
    "<span style=\"font-size: 15pt; font-weight: bold;\">151 Empty Reviews (Ratings only)</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb3025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§­ Testing scrape for: Anytime Fitness City Square Mall\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJDzz1mk8Z2jER9spstsimgQE\n",
      "âœ… Chrome WebDriver initialized successfully.\n",
      "\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "â³ No new reviews found. Waiting... (1/5)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 60 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 6: Found 60 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 7: Found 60 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 8: Found 60 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 9: Found 40 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 10: Found 80 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 11: Found 40 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 12: Found 60 new reviews (Total: 290)\n",
      "ðŸ“Š Iteration 13: Found 60 new reviews (Total: 320)\n",
      "ðŸ“Š Iteration 14: Found 60 new reviews (Total: 350)\n",
      "ðŸ“Š Iteration 15: Found 60 new reviews (Total: 380)\n",
      "ðŸ“Š Iteration 16: Found 40 new reviews (Total: 390)\n",
      "â³ No new reviews found. Waiting... (1/5)\n",
      "ðŸ“Š Iteration 18: Found 60 new reviews (Total: 430)\n",
      "ðŸ“Š Iteration 19: Found 40 new reviews (Total: 440)\n",
      "ðŸ“Š Iteration 20: Found 40 new reviews (Total: 460)\n",
      "ðŸ“Š Iteration 21: Found 40 new reviews (Total: 480)\n",
      "ðŸ“Š Iteration 22: Found 40 new reviews (Total: 500)\n",
      "ðŸ“Š Iteration 23: Found 40 new reviews (Total: 520)\n",
      "ðŸ“Š Iteration 24: Found 40 new reviews (Total: 540)\n",
      "ðŸ“Š Iteration 25: Found 40 new reviews (Total: 560)\n",
      "ðŸ“Š Iteration 26: Found 40 new reviews (Total: 580)\n",
      "ðŸ“Š Iteration 27: Found 40 new reviews (Total: 600)\n",
      "ðŸ“Š Iteration 28: Found 40 new reviews (Total: 620)\n",
      "ðŸ“Š Iteration 29: Found 40 new reviews (Total: 640)\n",
      "ðŸ“Š Iteration 30: Found 40 new reviews (Total: 660)\n",
      "ðŸ“Š Iteration 31: Found 40 new reviews (Total: 680)\n",
      "ðŸ“Š Iteration 32: Found 40 new reviews (Total: 700)\n",
      "ðŸ“Š Iteration 33: Found 40 new reviews (Total: 720)\n",
      "ðŸ“Š Iteration 34: Found 40 new reviews (Total: 740)\n",
      "ðŸ“Š Iteration 35: Found 40 new reviews (Total: 760)\n",
      "ðŸ“Š Iteration 36: Found 40 new reviews (Total: 780)\n",
      "ðŸ“Š Iteration 37: Found 40 new reviews (Total: 800)\n",
      "ðŸ“Š Iteration 38: Found 40 new reviews (Total: 820)\n",
      "ðŸ“Š Iteration 39: Found 40 new reviews (Total: 840)\n",
      "ðŸ“Š Iteration 40: Found 40 new reviews (Total: 860)\n",
      "ðŸ“Š Iteration 41: Found 40 new reviews (Total: 880)\n",
      "ðŸ“Š Iteration 42: Found 40 new reviews (Total: 900)\n",
      "ðŸ“Š Iteration 43: Found 40 new reviews (Total: 920)\n",
      "ðŸ“Š Iteration 44: Found 40 new reviews (Total: 940)\n",
      "ðŸ“Š Iteration 45: Found 40 new reviews (Total: 960)\n",
      "ðŸ“Š Iteration 46: Found 26 new reviews (Total: 966)\n",
      "â³ No new reviews found. Waiting... (1/5)\n",
      "â³ No new reviews found. Waiting... (3/5)\n",
      "â³ No new reviews found. Waiting... (5/5)\n",
      "âœ‹ Reached end of reviews.\n",
      "\n",
      "âœ… Saved 900 unique reviews to 'Reviews/Anytime Fitness City Square Mall_reviews.csv'\n",
      "ðŸ“„ Found 0 reviews that were ratings only (no text).\n",
      "ðŸ“ˆ Review breakdown by rating:\n",
      "rating\n",
      "5    844\n",
      "4     26\n",
      "3      9\n",
      "2      3\n",
      "1     18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# LOAD OUTLET DATA\n",
    "# ==============================\n",
    "df_outlets = pd.read_csv(\"top_5_outlets.csv\") \n",
    "\n",
    "# Pick 2nd top outlet\n",
    "outlet_name = df_outlets.iloc[1][\"name\"]\n",
    "outlet_url = df_outlets.iloc[1][\"maps_url\"]\n",
    "\n",
    "print(f\"ðŸ§­ Testing scrape for: {outlet_name}\")\n",
    "print(f\"ðŸ”— URL: {outlet_url}\")\n",
    "\n",
    "# ==============================\n",
    "# SETUP CHROME DRIVER\n",
    "# ==============================\n",
    "options = ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"--lang=en-US\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "# options.add_argument(\"--headless\")  # uncomment to run in background\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "wait = WebDriverWait(driver, 15)\n",
    "actions = ActionChains(driver)\n",
    "print(\"âœ… Chrome WebDriver initialized successfully.\")\n",
    "\n",
    "# ==============================\n",
    "# OPEN OUTLET PAGE AND CLICK REVIEWS\n",
    "# ==============================\n",
    "driver.get(outlet_url)\n",
    "time.sleep(3)\n",
    "\n",
    "# Click the \"Reviews\" button\n",
    "reviews_button = wait.until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label, \"Reviews for\")]'))\n",
    ")\n",
    "reviews_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# ==============================\n",
    "# SCROLL AND SCRAPE REVIEWS\n",
    "# ==============================\n",
    "# Find the scrollable container - this is the key fix\n",
    "scrollable_div = wait.until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]'))\n",
    ")\n",
    "\n",
    "all_reviews_data = []\n",
    "seen_review_ids = set()\n",
    "no_text_rating_count = 0\n",
    "\n",
    "scroll_pause = 2  \n",
    "no_new_count = 0\n",
    "max_no_new = 5  # Increased patience\n",
    "previous_height = 0\n",
    "\n",
    "print(\"\\nðŸ”„ Starting to scroll and collect reviews...\")\n",
    "\n",
    "scroll_iteration = 0\n",
    "while True:\n",
    "    scroll_iteration += 1\n",
    "    \n",
    "    # Get current scroll height\n",
    "    current_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # Find all reviews currently loaded\n",
    "    review_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "    new_reviews = [r for r in review_elements if r.get_attribute(\"data-review-id\") not in seen_review_ids]\n",
    "\n",
    "    if new_reviews:\n",
    "        no_new_count = 0\n",
    "        print(f\"ðŸ“Š Iteration {scroll_iteration}: Found {len(new_reviews)} new reviews (Total: {len(seen_review_ids) + len(new_reviews)})\")\n",
    "    else:\n",
    "        no_new_count += 1\n",
    "        print(f\"â³ No new reviews found. Waiting... ({no_new_count}/{max_no_new})\")\n",
    "        if no_new_count >= max_no_new:\n",
    "            print(\"âœ‹ Reached end of reviews.\")\n",
    "            break\n",
    "\n",
    "    for r in new_reviews:\n",
    "        review_id = r.get_attribute(\"data-review-id\")\n",
    "        \n",
    "        # Skip if already processed\n",
    "        if review_id in seen_review_ids:\n",
    "            continue\n",
    "            \n",
    "        seen_review_ids.add(review_id)\n",
    "        \n",
    "        try:\n",
    "            # Expand truncated review text (\"More\" button)\n",
    "            try:\n",
    "                more_button = r.find_element(By.CLASS_NAME, 'w8nwRe')\n",
    "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(0.15)\n",
    "            except (NoSuchElementException, StaleElementReferenceException):\n",
    "                pass\n",
    "\n",
    "            # Extract review data\n",
    "            author_name = r.find_element(By.CLASS_NAME, 'd4r55').text\n",
    "            \n",
    "            # Check if this is an owner response (no rating element)\n",
    "            rating_elements = r.find_elements(By.CLASS_NAME, 'kvMYJc')\n",
    "            if not rating_elements:\n",
    "                continue  # Skip owner responses\n",
    "            \n",
    "            rating_element = rating_elements[0]\n",
    "            rating_text = rating_element.get_attribute('aria-label')\n",
    "            star_rating = int(rating_text.split(' ')[0])\n",
    "            review_text = r.find_element(By.CLASS_NAME, 'wiI7pd').text.strip()\n",
    "\n",
    "            if not review_text:\n",
    "                no_text_rating_count += 1\n",
    "\n",
    "            try:\n",
    "                date_element = r.find_element(By.CLASS_NAME, 'rsqApe')\n",
    "                posting_date = date_element.text\n",
    "            except NoSuchElementException:\n",
    "                posting_date = \"Date not found\"\n",
    "\n",
    "            all_reviews_data.append({\n",
    "                \"outlet\": outlet_name,\n",
    "                \"author\": author_name,\n",
    "                \"rating\": star_rating,\n",
    "                \"text\": review_text,\n",
    "                \"date_posted\": posting_date\n",
    "            })\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # Scroll down smoothly - KEY FIX: Multiple small scrolls\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\n",
    "            \"arguments[0].scrollBy(0, arguments[0].scrollHeight / 3);\", \n",
    "            scrollable_div\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Additional wait for lazy loading\n",
    "    time.sleep(scroll_pause)\n",
    "    \n",
    "    new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # If the scroll height hasn't changed AND we didn't find new reviews, increment the patience counter\n",
    "    if new_height == previous_height:\n",
    "        if not new_reviews:\n",
    "            no_new_count += 1\n",
    "        # If new_reviews *was* found but the height didn't change, we reset the patience counter\n",
    "        # because the page likely rendered hidden reviews without scrolling.\n",
    "    else:\n",
    "        no_new_count = 0 # Reset patience if scrolling was successful\n",
    "        \n",
    "    previous_height = new_height\n",
    "\n",
    "    # After your existing scroll logic, try scrolling back up occasionally\n",
    "    if scroll_iteration % 10 == 0:\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, -500);\", scrollable_div)\n",
    "        time.sleep(0.5)\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, 1000);\", scrollable_div)    \n",
    "\n",
    "# ==============================\n",
    "# SAVE RESULTS\n",
    "# ==============================\n",
    "driver.quit()\n",
    "\n",
    "if all_reviews_data:\n",
    "    os.makedirs(\"Reviews/Best\", exist_ok=True)\n",
    "    output_filename = os.path.join(\"Reviews/Best\", f\"{outlet_name}_reviews.csv\")\n",
    "    df_reviews = pd.DataFrame(all_reviews_data)\n",
    "    \n",
    "    # Remove duplicates based on author + text combination\n",
    "    initial_count = len(df_reviews)\n",
    "    df_reviews = df_reviews.drop_duplicates(subset=['author', 'text'], keep='first')\n",
    "    final_count = len(df_reviews)\n",
    "    \n",
    "    if initial_count > final_count:\n",
    "        print(f\"âš ï¸  Removed {initial_count - final_count} duplicate reviews\")\n",
    "    \n",
    "    df_reviews.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nâœ… Saved {final_count} unique reviews to '{output_filename}'\")\n",
    "    print(f\"ðŸ“„ Found {no_text_rating_count} reviews that were ratings only (no text).\")\n",
    "    print(f\"ðŸ“ˆ Review breakdown by rating:\")\n",
    "    print(df_reviews['rating'].value_counts().sort_index(ascending=False))\n",
    "else:\n",
    "    print(\"âŒ No reviews were scraped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f280c",
   "metadata": {},
   "source": [
    "### REVIEW EXTRACTION: (3) BEDOK 85\n",
    "#### 1047 Ratings, 855 Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3510a2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§­ Testing scrape for: Anytime Fitness Bedok 85\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJa71bPCI92jERWtJc9IYBGUo\n",
      "âœ… Chrome WebDriver initialized successfully.\n",
      "\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 3: Found 40 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 4: Found 60 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 5: Found 60 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 6: Found 60 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 7: Found 60 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 8: Found 60 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 9: Found 60 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 10: Found 60 new reviews (Total: 280)\n",
      "ðŸ“Š Iteration 11: Found 60 new reviews (Total: 310)\n",
      "ðŸ“Š Iteration 12: Found 60 new reviews (Total: 340)\n",
      "ðŸ“Š Iteration 13: Found 60 new reviews (Total: 370)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 360)\n",
      "ðŸ“Š Iteration 15: Found 60 new reviews (Total: 410)\n",
      "ðŸ“Š Iteration 16: Found 60 new reviews (Total: 440)\n",
      "ðŸ“Š Iteration 17: Found 60 new reviews (Total: 470)\n",
      "ðŸ“Š Iteration 18: Found 60 new reviews (Total: 500)\n",
      "ðŸ“Š Iteration 19: Found 40 new reviews (Total: 510)\n",
      "ðŸ“Š Iteration 20: Found 40 new reviews (Total: 530)\n",
      "ðŸ“Š Iteration 21: Found 40 new reviews (Total: 550)\n",
      "ðŸ“Š Iteration 22: Found 40 new reviews (Total: 570)\n",
      "ðŸ“Š Iteration 23: Found 40 new reviews (Total: 590)\n",
      "ðŸ“Š Iteration 24: Found 40 new reviews (Total: 610)\n",
      "ðŸ“Š Iteration 25: Found 40 new reviews (Total: 630)\n",
      "ðŸ“Š Iteration 26: Found 40 new reviews (Total: 650)\n",
      "ðŸ“Š Iteration 27: Found 40 new reviews (Total: 670)\n",
      "ðŸ“Š Iteration 28: Found 40 new reviews (Total: 690)\n",
      "ðŸ“Š Iteration 29: Found 40 new reviews (Total: 710)\n",
      "ðŸ“Š Iteration 30: Found 40 new reviews (Total: 730)\n",
      "ðŸ“Š Iteration 31: Found 40 new reviews (Total: 750)\n",
      "ðŸ“Š Iteration 32: Found 40 new reviews (Total: 770)\n",
      "ðŸ“Š Iteration 33: Found 40 new reviews (Total: 790)\n",
      "ðŸ“Š Iteration 34: Found 40 new reviews (Total: 810)\n",
      "ðŸ“Š Iteration 35: Found 40 new reviews (Total: 830)\n",
      "ðŸ“Š Iteration 36: Found 40 new reviews (Total: 850)\n",
      "ðŸ“Š Iteration 37: Found 40 new reviews (Total: 870)\n",
      "ðŸ“Š Iteration 38: Found 40 new reviews (Total: 890)\n",
      "ðŸ“Š Iteration 39: Found 40 new reviews (Total: 910)\n",
      "ðŸ“Š Iteration 40: Found 40 new reviews (Total: 930)\n",
      "ðŸ“Š Iteration 41: Found 40 new reviews (Total: 950)\n",
      "ðŸ“Š Iteration 42: Found 40 new reviews (Total: 970)\n",
      "ðŸ“Š Iteration 43: Found 40 new reviews (Total: 990)\n",
      "ðŸ“Š Iteration 44: Found 40 new reviews (Total: 1010)\n",
      "ðŸ“Š Iteration 45: Found 26 new reviews (Total: 1016)\n",
      "â³ No new reviews found. Waiting... (1/5)\n",
      "â³ No new reviews found. Waiting... (3/5)\n",
      "â³ No new reviews found. Waiting... (5/5)\n",
      "âœ‹ Reached end of reviews.\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š SCRAPING SUMMARY FOR: Anytime Fitness Bedok 85\n",
      "============================================================\n",
      "Total review elements found:     1003\n",
      "Owner responses (skipped):       407\n",
      "Extraction errors (failed):      0\n",
      "Successfully processed:          596\n",
      "  - With text:                   449\n",
      "  - Rating-only (no text):       147\n",
      "Total extracted to list:         596\n",
      "Duplicates removed:              0\n",
      "Final unique reviews saved:      596\n",
      "============================================================\n",
      "ðŸ“„ Review breakdown by rating:\n",
      "rating\n",
      "5    582\n",
      "4     10\n",
      "2      1\n",
      "1      3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# LOAD OUTLET DATA\n",
    "# ==============================\n",
    "df_outlets = pd.read_csv(\"top_5_outlets.csv\") \n",
    "\n",
    "# Pick 2nd top outlet\n",
    "outlet_name = df_outlets.iloc[2][\"name\"]\n",
    "outlet_url = df_outlets.iloc[2][\"maps_url\"]\n",
    "\n",
    "print(f\"ðŸ§­ Testing scrape for: {outlet_name}\")\n",
    "print(f\"ðŸ”— URL: {outlet_url}\")\n",
    "\n",
    "# ==============================\n",
    "# SETUP CHROME DRIVER\n",
    "# ==============================\n",
    "options = ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"--lang=en-US\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "# options.add_argument(\"--headless\")  # uncomment to run in background\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "wait = WebDriverWait(driver, 15)\n",
    "actions = ActionChains(driver)\n",
    "print(\"âœ… Chrome WebDriver initialized successfully.\")\n",
    "\n",
    "# ==============================\n",
    "# OPEN OUTLET PAGE AND CLICK REVIEWS\n",
    "# ==============================\n",
    "driver.get(outlet_url)\n",
    "time.sleep(3)\n",
    "\n",
    "# Click the \"Reviews\" button\n",
    "reviews_button = wait.until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label, \"Reviews for\")]'))\n",
    ")\n",
    "reviews_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# ==============================\n",
    "# SCROLL AND SCRAPE REVIEWS\n",
    "# ==============================\n",
    "# Find the scrollable container - this is the key fix\n",
    "scrollable_div = wait.until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]'))\n",
    ")\n",
    "\n",
    "all_reviews_data = []\n",
    "seen_review_ids = set()\n",
    "\n",
    "# TRACKING COUNTERS\n",
    "total_review_elements_found = 0\n",
    "empty_text_reviews = 0\n",
    "extraction_errors = 0\n",
    "owner_responses_skipped = 0\n",
    "\n",
    "scroll_pause = 2  \n",
    "no_new_count = 0\n",
    "max_no_new = 5\n",
    "previous_height = 0\n",
    "\n",
    "print(\"\\nðŸ”„ Starting to scroll and collect reviews...\")\n",
    "\n",
    "scroll_iteration = 0\n",
    "while True:\n",
    "    scroll_iteration += 1\n",
    "    \n",
    "    # Get current scroll height\n",
    "    current_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # Find all reviews currently loaded\n",
    "    review_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "    new_reviews = [r for r in review_elements if r.get_attribute(\"data-review-id\") not in seen_review_ids]\n",
    "\n",
    "    if new_reviews:\n",
    "        no_new_count = 0\n",
    "        print(f\"ðŸ“Š Iteration {scroll_iteration}: Found {len(new_reviews)} new reviews (Total: {len(seen_review_ids) + len(new_reviews)})\")\n",
    "    else:\n",
    "        no_new_count += 1\n",
    "        print(f\"â³ No new reviews found. Waiting... ({no_new_count}/{max_no_new})\")\n",
    "        if no_new_count >= max_no_new:\n",
    "            print(\"âœ‹ Reached end of reviews.\")\n",
    "            break\n",
    "\n",
    "    for r in new_reviews:\n",
    "        review_id = r.get_attribute(\"data-review-id\")\n",
    "        \n",
    "        # Skip if already processed\n",
    "        if review_id in seen_review_ids:\n",
    "            continue\n",
    "            \n",
    "        seen_review_ids.add(review_id)\n",
    "        total_review_elements_found += 1\n",
    "        \n",
    "        try:\n",
    "            # Expand truncated review text (\"More\" button)\n",
    "            try:\n",
    "                more_button = r.find_element(By.CLASS_NAME, 'w8nwRe')\n",
    "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(0.15)\n",
    "            except (NoSuchElementException, StaleElementReferenceException):\n",
    "                pass\n",
    "\n",
    "            # Re-fetch the element from DOM to avoid stale references\n",
    "            try:\n",
    "                r = driver.find_element(By.XPATH, f'//div[@data-review-id=\"{review_id}\"]')\n",
    "            except NoSuchElementException:\n",
    "                extraction_errors += 1\n",
    "                continue\n",
    "\n",
    "            # Extract author (gracefully handle missing)\n",
    "            author_elems = r.find_elements(By.CLASS_NAME, 'd4r55')\n",
    "            author_name = author_elems[0].text if author_elems else ''\n",
    "            \n",
    "            # Check if this is an owner response by looking for the \"Response from the owner\" label\n",
    "            owner_response_labels = r.find_elements(By.CLASS_NAME, 'fontTitleSmall')\n",
    "            is_owner_response = any('response from the owner' in label.text.lower() for label in owner_response_labels)\n",
    "            if is_owner_response:\n",
    "                owner_responses_skipped += 1\n",
    "                continue  # Skip owner responses\n",
    "            \n",
    "            # Extract rating\n",
    "            rating_elements = r.find_elements(By.CLASS_NAME, 'kvMYJc')\n",
    "            if not rating_elements:\n",
    "                star_rating = None\n",
    "            else:\n",
    "                rating_text = rating_elements[0].get_attribute('aria-label') or ''\n",
    "                try:\n",
    "                    star_rating = int(rating_text.split(' ')[0])\n",
    "                except (ValueError, IndexError):\n",
    "                    star_rating = None\n",
    "            \n",
    "            # Extract review text - use find_elements to avoid exceptions\n",
    "            text_elems = r.find_elements(By.CLASS_NAME, 'wiI7pd')\n",
    "            review_text = (text_elems[0].text or '').strip() if text_elems else ''\n",
    "            \n",
    "            # Track empty text reviews\n",
    "            if not review_text:\n",
    "                empty_text_reviews += 1\n",
    "\n",
    "            # Extract date (gracefully handle missing)\n",
    "            date_elems = r.find_elements(By.CLASS_NAME, 'rsqApe')\n",
    "            posting_date = date_elems[0].text if date_elems else \"Date not found\"\n",
    "\n",
    "            all_reviews_data.append({\n",
    "                \"outlet\": outlet_name,\n",
    "                \"author\": author_name,\n",
    "                \"rating\": star_rating,\n",
    "                \"text\": review_text,\n",
    "                \"date_posted\": posting_date,\n",
    "                \"review_id\": review_id\n",
    "            })\n",
    "        except Exception as e:\n",
    "            extraction_errors += 1\n",
    "            continue\n",
    "\n",
    "    # Scroll down smoothly - KEY FIX: Multiple small scrolls\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\n",
    "            \"arguments[0].scrollBy(0, arguments[0].scrollHeight / 3);\", \n",
    "            scrollable_div\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Additional wait for lazy loading\n",
    "    time.sleep(scroll_pause)\n",
    "    \n",
    "    new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # If the scroll height hasn't changed AND we didn't find new reviews, increment the patience counter\n",
    "    if new_height == previous_height:\n",
    "        if not new_reviews:\n",
    "            no_new_count += 1\n",
    "        # If new_reviews *was* found but the height didn't change, we reset the patience counter\n",
    "        # because the page likely rendered hidden reviews without scrolling.\n",
    "    else:\n",
    "        no_new_count = 0 # Reset patience if scrolling was successful\n",
    "        \n",
    "    previous_height = new_height\n",
    "\n",
    "    # After your existing scroll logic, try scrolling back up occasionally\n",
    "    if scroll_iteration % 10 == 0:\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, -500);\", scrollable_div)\n",
    "        time.sleep(0.5)\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, 1000);\", scrollable_div)    \n",
    "\n",
    "# ==============================\n",
    "# SAVE RESULTS\n",
    "# ==============================\n",
    "driver.quit()\n",
    "\n",
    "if all_reviews_data:\n",
    "    os.makedirs(\"Reviews\", exist_ok=True)\n",
    "    output_filename = os.path.join(\"Reviews\", f\"{outlet_name}_reviews.csv\")\n",
    "    df_reviews = pd.DataFrame(all_reviews_data)\n",
    "    \n",
    "    # Remove duplicates based on review_id (most reliable)\n",
    "    initial_count = len(df_reviews)\n",
    "    df_reviews = df_reviews.drop_duplicates(subset=['review_id'], keep='first')\n",
    "    final_count = len(df_reviews)\n",
    "    \n",
    "    if initial_count > final_count:\n",
    "        print(f\"âš ï¸  Removed {initial_count - final_count} duplicate reviews\")\n",
    "    \n",
    "    df_reviews.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ“Š SCRAPING SUMMARY FOR: {outlet_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total review elements found:     {total_review_elements_found}\")\n",
    "    print(f\"Owner responses (skipped):       {owner_responses_skipped}\")\n",
    "    print(f\"Extraction errors (failed):      {extraction_errors}\")\n",
    "    print(f\"Successfully processed:          {total_review_elements_found - extraction_errors - owner_responses_skipped}\")\n",
    "    print(f\"  - With text:                   {(total_review_elements_found - extraction_errors - owner_responses_skipped) - empty_text_reviews}\")\n",
    "    print(f\"  - Rating-only (no text):       {empty_text_reviews}\")\n",
    "    print(f\"Total extracted to list:         {len(all_reviews_data)}\")\n",
    "    print(f\"Duplicates removed:              {initial_count - final_count}\")\n",
    "    print(f\"Final unique reviews saved:      {final_count}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"ðŸ“„ Review breakdown by rating:\")\n",
    "    print(df_reviews['rating'].value_counts().sort_index(ascending=False))\n",
    "else:\n",
    "    print(\"âŒ No reviews were scraped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd97efb",
   "metadata": {},
   "source": [
    "### REVIEW EXTRACTION: (4) Bukit Timah Central\n",
    "#### 960 Ratings, 760 Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d0de39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§­ Testing scrape for: Anytime Fitness Bukit Timah Central\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJU5AB6_sb2jERZXpNUjEz7Fk\n",
      "âœ… Chrome WebDriver initialized successfully.\n",
      "\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 3: Found 40 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 4: Found 60 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 5: Found 60 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 6: Found 60 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 7: Found 60 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 8: Found 60 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 9: Found 60 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 10: Found 60 new reviews (Total: 280)\n",
      "ðŸ“Š Iteration 11: Found 60 new reviews (Total: 310)\n",
      "ðŸ“Š Iteration 12: Found 60 new reviews (Total: 340)\n",
      "â³ No new reviews found. Waiting... (1/5)\n",
      "ðŸ“Š Iteration 14: Found 80 new reviews (Total: 390)\n",
      "ðŸ“Š Iteration 15: Found 60 new reviews (Total: 410)\n",
      "ðŸ“Š Iteration 16: Found 60 new reviews (Total: 440)\n",
      "ðŸ“Š Iteration 17: Found 60 new reviews (Total: 470)\n",
      "ðŸ“Š Iteration 18: Found 60 new reviews (Total: 500)\n",
      "ðŸ“Š Iteration 19: Found 40 new reviews (Total: 510)\n",
      "ðŸ“Š Iteration 20: Found 40 new reviews (Total: 530)\n",
      "ðŸ“Š Iteration 21: Found 40 new reviews (Total: 550)\n",
      "ðŸ“Š Iteration 22: Found 40 new reviews (Total: 570)\n",
      "ðŸ“Š Iteration 23: Found 40 new reviews (Total: 590)\n",
      "ðŸ“Š Iteration 24: Found 40 new reviews (Total: 610)\n",
      "ðŸ“Š Iteration 25: Found 40 new reviews (Total: 630)\n",
      "ðŸ“Š Iteration 26: Found 40 new reviews (Total: 650)\n",
      "ðŸ“Š Iteration 27: Found 40 new reviews (Total: 670)\n",
      "ðŸ“Š Iteration 28: Found 40 new reviews (Total: 690)\n",
      "ðŸ“Š Iteration 29: Found 40 new reviews (Total: 710)\n",
      "ðŸ“Š Iteration 30: Found 40 new reviews (Total: 730)\n",
      "ðŸ“Š Iteration 31: Found 40 new reviews (Total: 750)\n",
      "ðŸ“Š Iteration 32: Found 40 new reviews (Total: 770)\n",
      "ðŸ“Š Iteration 33: Found 40 new reviews (Total: 790)\n",
      "ðŸ“Š Iteration 34: Found 40 new reviews (Total: 810)\n",
      "ðŸ“Š Iteration 35: Found 40 new reviews (Total: 830)\n",
      "ðŸ“Š Iteration 36: Found 40 new reviews (Total: 850)\n",
      "ðŸ“Š Iteration 37: Found 40 new reviews (Total: 870)\n",
      "ðŸ“Š Iteration 38: Found 40 new reviews (Total: 890)\n",
      "ðŸ“Š Iteration 39: Found 24 new reviews (Total: 894)\n",
      "â³ No new reviews found. Waiting... (1/5)\n",
      "â³ No new reviews found. Waiting... (3/5)\n",
      "â³ No new reviews found. Waiting... (5/5)\n",
      "âœ‹ Reached end of reviews.\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š SCRAPING SUMMARY FOR: Anytime Fitness Bukit Timah Central\n",
      "============================================================\n",
      "Total review elements found:     882\n",
      "Owner responses (skipped):       122\n",
      "Extraction errors (failed):      0\n",
      "Successfully processed:          760\n",
      "  - With text:                   596\n",
      "  - Rating-only (no text):       164\n",
      "Total extracted to list:         760\n",
      "Duplicates removed:              0\n",
      "Final unique reviews saved:      760\n",
      "============================================================\n",
      "ðŸ“„ Review breakdown by rating:\n",
      "rating\n",
      "5    736\n",
      "4     14\n",
      "3      2\n",
      "2      2\n",
      "1      6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# LOAD OUTLET DATA\n",
    "# ==============================\n",
    "df_outlets = pd.read_csv(\"top_5_outlets.csv\") \n",
    "\n",
    "# Pick 2nd top outlet\n",
    "outlet_name = df_outlets.iloc[3][\"name\"]\n",
    "outlet_url = df_outlets.iloc[3][\"maps_url\"]\n",
    "\n",
    "print(f\"ðŸ§­ Testing scrape for: {outlet_name}\")\n",
    "print(f\"ðŸ”— URL: {outlet_url}\")\n",
    "\n",
    "# ==============================\n",
    "# SETUP CHROME DRIVER\n",
    "# ==============================\n",
    "options = ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"--lang=en-US\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "# options.add_argument(\"--headless\")  # uncomment to run in background\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "wait = WebDriverWait(driver, 15)\n",
    "actions = ActionChains(driver)\n",
    "print(\"âœ… Chrome WebDriver initialized successfully.\")\n",
    "\n",
    "# ==============================\n",
    "# OPEN OUTLET PAGE AND CLICK REVIEWS\n",
    "# ==============================\n",
    "driver.get(outlet_url)\n",
    "time.sleep(3)\n",
    "\n",
    "# Click the \"Reviews\" button\n",
    "reviews_button = wait.until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label, \"Reviews for\")]'))\n",
    ")\n",
    "reviews_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# ==============================\n",
    "# SCROLL AND SCRAPE REVIEWS\n",
    "# ==============================\n",
    "# Find the scrollable container - this is the key fix\n",
    "scrollable_div = wait.until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]'))\n",
    ")\n",
    "\n",
    "all_reviews_data = []\n",
    "seen_review_ids = set()\n",
    "\n",
    "# TRACKING COUNTERS\n",
    "total_review_elements_found = 0\n",
    "empty_text_reviews = 0\n",
    "extraction_errors = 0\n",
    "owner_responses_skipped = 0\n",
    "\n",
    "scroll_pause = 2  \n",
    "no_new_count = 0\n",
    "max_no_new = 5\n",
    "previous_height = 0\n",
    "\n",
    "print(\"\\nðŸ”„ Starting to scroll and collect reviews...\")\n",
    "\n",
    "scroll_iteration = 0\n",
    "while True:\n",
    "    scroll_iteration += 1\n",
    "    \n",
    "    # Get current scroll height\n",
    "    current_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # Find all reviews currently loaded\n",
    "    review_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "    new_reviews = [r for r in review_elements if r.get_attribute(\"data-review-id\") not in seen_review_ids]\n",
    "\n",
    "    if new_reviews:\n",
    "        no_new_count = 0\n",
    "        print(f\"ðŸ“Š Iteration {scroll_iteration}: Found {len(new_reviews)} new reviews (Total: {len(seen_review_ids) + len(new_reviews)})\")\n",
    "    else:\n",
    "        no_new_count += 1\n",
    "        print(f\"â³ No new reviews found. Waiting... ({no_new_count}/{max_no_new})\")\n",
    "        if no_new_count >= max_no_new:\n",
    "            print(\"âœ‹ Reached end of reviews.\")\n",
    "            break\n",
    "\n",
    "    for r in new_reviews:\n",
    "        review_id = r.get_attribute(\"data-review-id\")\n",
    "        \n",
    "        # Skip if already processed\n",
    "        if review_id in seen_review_ids:\n",
    "            continue\n",
    "            \n",
    "        seen_review_ids.add(review_id)\n",
    "        total_review_elements_found += 1\n",
    "        \n",
    "        try:\n",
    "            # Expand truncated review text (\"More\" button)\n",
    "            try:\n",
    "                more_button = r.find_element(By.CLASS_NAME, 'w8nwRe')\n",
    "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(0.15)\n",
    "            except (NoSuchElementException, StaleElementReferenceException):\n",
    "                pass\n",
    "\n",
    "            # Re-fetch the element from DOM to avoid stale references\n",
    "            try:\n",
    "                r = driver.find_element(By.XPATH, f'//div[@data-review-id=\"{review_id}\"]')\n",
    "            except NoSuchElementException:\n",
    "                extraction_errors += 1\n",
    "                continue\n",
    "\n",
    "            # Extract author (gracefully handle missing)\n",
    "            author_elems = r.find_elements(By.CLASS_NAME, 'd4r55')\n",
    "            author_name = author_elems[0].text if author_elems else ''\n",
    "            \n",
    "            # Check if this is an owner response by looking for the \"Response from the owner\" label\n",
    "            owner_response_labels = r.find_elements(By.CLASS_NAME, 'fontTitleSmall')\n",
    "            is_owner_response = any('response from the owner' in label.text.lower() for label in owner_response_labels)\n",
    "            if is_owner_response:\n",
    "                owner_responses_skipped += 1\n",
    "                continue  # Skip owner responses\n",
    "            \n",
    "            # Extract rating\n",
    "            rating_elements = r.find_elements(By.CLASS_NAME, 'kvMYJc')\n",
    "            if not rating_elements:\n",
    "                star_rating = None\n",
    "            else:\n",
    "                rating_text = rating_elements[0].get_attribute('aria-label') or ''\n",
    "                try:\n",
    "                    star_rating = int(rating_text.split(' ')[0])\n",
    "                except (ValueError, IndexError):\n",
    "                    star_rating = None\n",
    "            \n",
    "            # Extract review text - use find_elements to avoid exceptions\n",
    "            text_elems = r.find_elements(By.CLASS_NAME, 'wiI7pd')\n",
    "            review_text = (text_elems[0].text or '').strip() if text_elems else ''\n",
    "            \n",
    "            # Track empty text reviews\n",
    "            if not review_text:\n",
    "                empty_text_reviews += 1\n",
    "\n",
    "            # Extract date (gracefully handle missing)\n",
    "            date_elems = r.find_elements(By.CLASS_NAME, 'rsqApe')\n",
    "            posting_date = date_elems[0].text if date_elems else \"Date not found\"\n",
    "\n",
    "            all_reviews_data.append({\n",
    "                \"outlet\": outlet_name,\n",
    "                \"author\": author_name,\n",
    "                \"rating\": star_rating,\n",
    "                \"text\": review_text,\n",
    "                \"date_posted\": posting_date,\n",
    "                \"review_id\": review_id\n",
    "            })\n",
    "        except Exception as e:\n",
    "            extraction_errors += 1\n",
    "            continue\n",
    "\n",
    "    # Scroll down smoothly - KEY FIX: Multiple small scrolls\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\n",
    "            \"arguments[0].scrollBy(0, arguments[0].scrollHeight / 3);\", \n",
    "            scrollable_div\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Additional wait for lazy loading\n",
    "    time.sleep(scroll_pause)\n",
    "    \n",
    "    new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # If the scroll height hasn't changed AND we didn't find new reviews, increment the patience counter\n",
    "    if new_height == previous_height:\n",
    "        if not new_reviews:\n",
    "            no_new_count += 1\n",
    "        # If new_reviews *was* found but the height didn't change, we reset the patience counter\n",
    "        # because the page likely rendered hidden reviews without scrolling.\n",
    "    else:\n",
    "        no_new_count = 0 # Reset patience if scrolling was successful\n",
    "        \n",
    "    previous_height = new_height\n",
    "\n",
    "    # After your existing scroll logic, try scrolling back up occasionally\n",
    "    if scroll_iteration % 10 == 0:\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, -500);\", scrollable_div)\n",
    "        time.sleep(0.5)\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, 1000);\", scrollable_div)    \n",
    "\n",
    "# ==============================\n",
    "# SAVE RESULTS\n",
    "# ==============================\n",
    "driver.quit()\n",
    "\n",
    "if all_reviews_data:\n",
    "    os.makedirs(\"Reviews\", exist_ok=True)\n",
    "    output_filename = os.path.join(\"Reviews\", f\"{outlet_name}_reviews.csv\")\n",
    "    df_reviews = pd.DataFrame(all_reviews_data)\n",
    "    \n",
    "    # Remove duplicates based on review_id (most reliable)\n",
    "    initial_count = len(df_reviews)\n",
    "    df_reviews = df_reviews.drop_duplicates(subset=['review_id'], keep='first')\n",
    "    final_count = len(df_reviews)\n",
    "    \n",
    "    if initial_count > final_count:\n",
    "        print(f\"âš ï¸  Removed {initial_count - final_count} duplicate reviews\")\n",
    "    \n",
    "    df_reviews.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ“Š SCRAPING SUMMARY FOR: {outlet_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total review elements found:     {total_review_elements_found}\")\n",
    "    print(f\"Owner responses (skipped):       {owner_responses_skipped}\")\n",
    "    print(f\"Extraction errors (failed):      {extraction_errors}\")\n",
    "    print(f\"Successfully processed:          {total_review_elements_found - extraction_errors - owner_responses_skipped}\")\n",
    "    print(f\"  - With text:                   {(total_review_elements_found - extraction_errors - owner_responses_skipped) - empty_text_reviews}\")\n",
    "    print(f\"  - Rating-only (no text):       {empty_text_reviews}\")\n",
    "    print(f\"Total extracted to list:         {len(all_reviews_data)}\")\n",
    "    print(f\"Duplicates removed:              {initial_count - final_count}\")\n",
    "    print(f\"Final unique reviews saved:      {final_count}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"ðŸ“„ Review breakdown by rating:\")\n",
    "    print(df_reviews['rating'].value_counts().sort_index(ascending=False))\n",
    "else:\n",
    "    print(\"âŒ No reviews were scraped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938649bf",
   "metadata": {},
   "source": [
    "### REVIEW EXTRACTION: (5) Buona Vista\n",
    "#### 837 Ratings, 733 Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f64b1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§­ Testing scrape for: Anytime Fitness Buona Vista\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJS1v-9jQb2jER7XzNEUFv8uM\n",
      "âœ… Chrome WebDriver initialized successfully.\n",
      "\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 3: Found 40 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 4: Found 60 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 5: Found 60 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 6: Found 60 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 7: Found 60 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 8: Found 60 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 9: Found 60 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 10: Found 60 new reviews (Total: 280)\n",
      "ðŸ“Š Iteration 11: Found 60 new reviews (Total: 310)\n",
      "ðŸ“Š Iteration 12: Found 60 new reviews (Total: 340)\n",
      "ðŸ“Š Iteration 13: Found 40 new reviews (Total: 350)\n",
      "ðŸ“Š Iteration 14: Found 60 new reviews (Total: 390)\n",
      "ðŸ“Š Iteration 15: Found 40 new reviews (Total: 400)\n",
      "ðŸ“Š Iteration 16: Found 40 new reviews (Total: 420)\n",
      "ðŸ“Š Iteration 17: Found 40 new reviews (Total: 440)\n",
      "ðŸ“Š Iteration 18: Found 60 new reviews (Total: 480)\n",
      "ðŸ“Š Iteration 19: Found 40 new reviews (Total: 490)\n",
      "ðŸ“Š Iteration 20: Found 40 new reviews (Total: 510)\n",
      "ðŸ“Š Iteration 21: Found 40 new reviews (Total: 530)\n",
      "ðŸ“Š Iteration 22: Found 40 new reviews (Total: 550)\n",
      "ðŸ“Š Iteration 23: Found 40 new reviews (Total: 570)\n",
      "ðŸ“Š Iteration 24: Found 40 new reviews (Total: 590)\n",
      "ðŸ“Š Iteration 25: Found 40 new reviews (Total: 610)\n",
      "ðŸ“Š Iteration 26: Found 40 new reviews (Total: 630)\n",
      "ðŸ“Š Iteration 27: Found 40 new reviews (Total: 650)\n",
      "ðŸ“Š Iteration 28: Found 40 new reviews (Total: 670)\n",
      "ðŸ“Š Iteration 29: Found 40 new reviews (Total: 690)\n",
      "ðŸ“Š Iteration 30: Found 40 new reviews (Total: 710)\n",
      "ðŸ“Š Iteration 31: Found 40 new reviews (Total: 730)\n",
      "ðŸ“Š Iteration 32: Found 40 new reviews (Total: 750)\n",
      "ðŸ“Š Iteration 33: Found 40 new reviews (Total: 770)\n",
      "ðŸ“Š Iteration 34: Found 40 new reviews (Total: 790)\n",
      "ðŸ“Š Iteration 35: Found 6 new reviews (Total: 776)\n",
      "â³ No new reviews found. Waiting... (1/5)\n",
      "â³ No new reviews found. Waiting... (3/5)\n",
      "â³ No new reviews found. Waiting... (5/5)\n",
      "âœ‹ Reached end of reviews.\n",
      "\n",
      "âœ… Saved 733 unique reviews to 'Reviews/Anytime Fitness Buona Vista_reviews.csv'\n",
      "ðŸ“„ Found 0 reviews that were ratings only (no text).\n",
      "ðŸ“ˆ Review breakdown by rating:\n",
      "rating\n",
      "5    684\n",
      "4     18\n",
      "3     13\n",
      "2      6\n",
      "1     12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# LOAD OUTLET DATA\n",
    "# ==============================\n",
    "df_outlets = pd.read_csv(\"top_5_outlets.csv\") \n",
    "\n",
    "# Pick 2nd top outlet\n",
    "outlet_name = df_outlets.iloc[4][\"name\"]\n",
    "outlet_url = df_outlets.iloc[4][\"maps_url\"]\n",
    "\n",
    "print(f\"ðŸ§­ Testing scrape for: {outlet_name}\")\n",
    "print(f\"ðŸ”— URL: {outlet_url}\")\n",
    "\n",
    "# ==============================\n",
    "# SETUP CHROME DRIVER\n",
    "# ==============================\n",
    "options = ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"--lang=en-US\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "# options.add_argument(\"--headless\")  # uncomment to run in background\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "wait = WebDriverWait(driver, 15)\n",
    "actions = ActionChains(driver)\n",
    "print(\"âœ… Chrome WebDriver initialized successfully.\")\n",
    "\n",
    "# ==============================\n",
    "# OPEN OUTLET PAGE AND CLICK REVIEWS\n",
    "# ==============================\n",
    "driver.get(outlet_url)\n",
    "time.sleep(3)\n",
    "\n",
    "# Click the \"Reviews\" button\n",
    "reviews_button = wait.until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label, \"Reviews for\")]'))\n",
    ")\n",
    "reviews_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# ==============================\n",
    "# SCROLL AND SCRAPE REVIEWS\n",
    "# ==============================\n",
    "# Find the scrollable container - this is the key fix\n",
    "scrollable_div = wait.until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]'))\n",
    ")\n",
    "\n",
    "all_reviews_data = []\n",
    "seen_review_ids = set()\n",
    "no_text_rating_count = 0\n",
    "\n",
    "scroll_pause = 2  \n",
    "no_new_count = 0\n",
    "max_no_new = 5  # Increased patience\n",
    "previous_height = 0\n",
    "\n",
    "print(\"\\nðŸ”„ Starting to scroll and collect reviews...\")\n",
    "\n",
    "scroll_iteration = 0\n",
    "while True:\n",
    "    scroll_iteration += 1\n",
    "    \n",
    "    # Get current scroll height\n",
    "    current_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # Find all reviews currently loaded\n",
    "    review_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "    new_reviews = [r for r in review_elements if r.get_attribute(\"data-review-id\") not in seen_review_ids]\n",
    "\n",
    "    if new_reviews:\n",
    "        no_new_count = 0\n",
    "        print(f\"ðŸ“Š Iteration {scroll_iteration}: Found {len(new_reviews)} new reviews (Total: {len(seen_review_ids) + len(new_reviews)})\")\n",
    "    else:\n",
    "        no_new_count += 1\n",
    "        print(f\"â³ No new reviews found. Waiting... ({no_new_count}/{max_no_new})\")\n",
    "        if no_new_count >= max_no_new:\n",
    "            print(\"âœ‹ Reached end of reviews.\")\n",
    "            break\n",
    "\n",
    "    for r in new_reviews:\n",
    "        review_id = r.get_attribute(\"data-review-id\")\n",
    "        \n",
    "        # Skip if already processed\n",
    "        if review_id in seen_review_ids:\n",
    "            continue\n",
    "            \n",
    "        seen_review_ids.add(review_id)\n",
    "        \n",
    "        try:\n",
    "            # Expand truncated review text (\"More\" button)\n",
    "            try:\n",
    "                more_button = r.find_element(By.CLASS_NAME, 'w8nwRe')\n",
    "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(0.15)\n",
    "            except (NoSuchElementException, StaleElementReferenceException):\n",
    "                pass\n",
    "\n",
    "            # Extract review data\n",
    "            author_name = r.find_element(By.CLASS_NAME, 'd4r55').text\n",
    "            \n",
    "            # Check if this is an owner response (no rating element)\n",
    "            rating_elements = r.find_elements(By.CLASS_NAME, 'kvMYJc')\n",
    "            if not rating_elements:\n",
    "                continue  # Skip owner responses\n",
    "            \n",
    "            rating_element = rating_elements[0]\n",
    "            rating_text = rating_element.get_attribute('aria-label')\n",
    "            star_rating = int(rating_text.split(' ')[0])\n",
    "            review_text = r.find_element(By.CLASS_NAME, 'wiI7pd').text.strip()\n",
    "\n",
    "            if not review_text:\n",
    "                no_text_rating_count += 1\n",
    "\n",
    "            try:\n",
    "                date_element = r.find_element(By.CLASS_NAME, 'rsqApe')\n",
    "                posting_date = date_element.text\n",
    "            except NoSuchElementException:\n",
    "                posting_date = \"Date not found\"\n",
    "\n",
    "            all_reviews_data.append({\n",
    "                \"outlet\": outlet_name,\n",
    "                \"author\": author_name,\n",
    "                \"rating\": star_rating,\n",
    "                \"text\": review_text,\n",
    "                \"date_posted\": posting_date\n",
    "            })\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # Scroll down smoothly - KEY FIX: Multiple small scrolls\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\n",
    "            \"arguments[0].scrollBy(0, arguments[0].scrollHeight / 3);\", \n",
    "            scrollable_div\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Additional wait for lazy loading\n",
    "    time.sleep(scroll_pause)\n",
    "    \n",
    "    new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # If the scroll height hasn't changed AND we didn't find new reviews, increment the patience counter\n",
    "    if new_height == previous_height:\n",
    "        if not new_reviews:\n",
    "            no_new_count += 1\n",
    "        # If new_reviews *was* found but the height didn't change, we reset the patience counter\n",
    "        # because the page likely rendered hidden reviews without scrolling.\n",
    "    else:\n",
    "        no_new_count = 0 # Reset patience if scrolling was successful\n",
    "        \n",
    "    previous_height = new_height\n",
    "\n",
    "    # After your existing scroll logic, try scrolling back up occasionally\n",
    "    if scroll_iteration % 10 == 0:\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, -500);\", scrollable_div)\n",
    "        time.sleep(0.5)\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, 1000);\", scrollable_div)    \n",
    "\n",
    "# ==============================\n",
    "# SAVE RESULTS\n",
    "# ==============================\n",
    "driver.quit()\n",
    "\n",
    "if all_reviews_data:\n",
    "    os.makedirs(\"Reviews\", exist_ok=True)\n",
    "    output_filename = os.path.join(\"Reviews\", f\"{outlet_name}_reviews.csv\")\n",
    "    df_reviews = pd.DataFrame(all_reviews_data)\n",
    "    \n",
    "    # Remove duplicates based on author + text combination\n",
    "    initial_count = len(df_reviews)\n",
    "    df_reviews = df_reviews.drop_duplicates(subset=['author', 'text'], keep='first')\n",
    "    final_count = len(df_reviews)\n",
    "    \n",
    "    if initial_count > final_count:\n",
    "        print(f\"âš ï¸  Removed {initial_count - final_count} duplicate reviews\")\n",
    "    \n",
    "    df_reviews.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nâœ… Saved {final_count} unique reviews to '{output_filename}'\")\n",
    "    print(f\"ðŸ“„ Found {no_text_rating_count} reviews that were ratings only (no text).\")\n",
    "    print(f\"ðŸ“ˆ Review breakdown by rating:\")\n",
    "    print(df_reviews['rating'].value_counts().sort_index(ascending=False))\n",
    "else:\n",
    "    print(\"âŒ No reviews were scraped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb6306",
   "metadata": {},
   "source": [
    "### *Bonus: REVIEW EXTRACTION- Outlet #6, Havelock Outram, 606 Ratings, 507 Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57a1ef1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§­ Testing scrape for: Anytime Fitness Havelock Outram\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJJyOThiMZ2jER9H-usPsO2g0\n",
      "âœ… Chrome WebDriver initialized successfully.\n",
      "\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "â³ No new reviews found. Waiting... (1/5)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 40 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 5: Found 60 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 6: Found 60 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 7: Found 60 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 8: Found 60 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 9: Found 60 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 10: Found 60 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 11: Found 60 new reviews (Total: 280)\n",
      "ðŸ“Š Iteration 12: Found 60 new reviews (Total: 310)\n",
      "ðŸ“Š Iteration 13: Found 60 new reviews (Total: 340)\n",
      "ðŸ“Š Iteration 14: Found 40 new reviews (Total: 350)\n",
      "ðŸ“Š Iteration 15: Found 60 new reviews (Total: 390)\n",
      "ðŸ“Š Iteration 16: Found 60 new reviews (Total: 420)\n",
      "ðŸ“Š Iteration 17: Found 60 new reviews (Total: 450)\n",
      "ðŸ“Š Iteration 18: Found 40 new reviews (Total: 460)\n",
      "ðŸ“Š Iteration 19: Found 40 new reviews (Total: 480)\n",
      "ðŸ“Š Iteration 20: Found 40 new reviews (Total: 500)\n",
      "ðŸ“Š Iteration 21: Found 40 new reviews (Total: 520)\n",
      "ðŸ“Š Iteration 22: Found 40 new reviews (Total: 540)\n",
      "ðŸ“Š Iteration 23: Found 40 new reviews (Total: 560)\n",
      "ðŸ“Š Iteration 24: Found 40 new reviews (Total: 580)\n",
      "ðŸ“Š Iteration 25: Found 40 new reviews (Total: 600)\n",
      "ðŸ“Š Iteration 26: Found 40 new reviews (Total: 620)\n",
      "ðŸ“Š Iteration 27: Found 12 new reviews (Total: 612)\n",
      "â³ No new reviews found. Waiting... (1/5)\n",
      "â³ No new reviews found. Waiting... (3/5)\n",
      "â³ No new reviews found. Waiting... (5/5)\n",
      "âœ‹ Reached end of reviews.\n",
      "\n",
      "âœ… Saved 507 unique reviews to 'Reviews/Anytime Fitness Havelock Outram_reviews.csv'\n",
      "ðŸ“„ Found 0 reviews that were ratings only (no text).\n",
      "ðŸ“ˆ Review breakdown by rating:\n",
      "rating\n",
      "5    488\n",
      "4      6\n",
      "3      7\n",
      "2      1\n",
      "1      5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# LOAD OUTLET DATA\n",
    "# ==============================\n",
    "df_outlets = pd.read_csv(\"top_5_outlets.csv\") \n",
    "\n",
    "# Pick 2nd top outlet\n",
    "outlet_name = df_outlets.iloc[5][\"name\"]\n",
    "outlet_url = df_outlets.iloc[5][\"maps_url\"]\n",
    "\n",
    "print(f\"ðŸ§­ Testing scrape for: {outlet_name}\")\n",
    "print(f\"ðŸ”— URL: {outlet_url}\")\n",
    "\n",
    "# ==============================\n",
    "# SETUP CHROME DRIVER\n",
    "# ==============================\n",
    "options = ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"--lang=en-US\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "# options.add_argument(\"--headless\")  # uncomment to run in background\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "wait = WebDriverWait(driver, 15)\n",
    "actions = ActionChains(driver)\n",
    "print(\"âœ… Chrome WebDriver initialized successfully.\")\n",
    "\n",
    "# ==============================\n",
    "# OPEN OUTLET PAGE AND CLICK REVIEWS\n",
    "# ==============================\n",
    "driver.get(outlet_url)\n",
    "time.sleep(3)\n",
    "\n",
    "# Click the \"Reviews\" button\n",
    "reviews_button = wait.until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label, \"Reviews for\")]'))\n",
    ")\n",
    "reviews_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# ==============================\n",
    "# SCROLL AND SCRAPE REVIEWS\n",
    "# ==============================\n",
    "# Find the scrollable container - this is the key fix\n",
    "scrollable_div = wait.until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]'))\n",
    ")\n",
    "\n",
    "all_reviews_data = []\n",
    "seen_review_ids = set()\n",
    "no_text_rating_count = 0\n",
    "\n",
    "scroll_pause = 2  \n",
    "no_new_count = 0\n",
    "max_no_new = 5  # Increased patience\n",
    "previous_height = 0\n",
    "\n",
    "print(\"\\nðŸ”„ Starting to scroll and collect reviews...\")\n",
    "\n",
    "scroll_iteration = 0\n",
    "while True:\n",
    "    scroll_iteration += 1\n",
    "    \n",
    "    # Get current scroll height\n",
    "    current_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # Find all reviews currently loaded\n",
    "    review_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "    new_reviews = [r for r in review_elements if r.get_attribute(\"data-review-id\") not in seen_review_ids]\n",
    "\n",
    "    if new_reviews:\n",
    "        no_new_count = 0\n",
    "        print(f\"ðŸ“Š Iteration {scroll_iteration}: Found {len(new_reviews)} new reviews (Total: {len(seen_review_ids) + len(new_reviews)})\")\n",
    "    else:\n",
    "        no_new_count += 1\n",
    "        print(f\"â³ No new reviews found. Waiting... ({no_new_count}/{max_no_new})\")\n",
    "        if no_new_count >= max_no_new:\n",
    "            print(\"âœ‹ Reached end of reviews.\")\n",
    "            break\n",
    "\n",
    "    for r in new_reviews:\n",
    "        review_id = r.get_attribute(\"data-review-id\")\n",
    "        \n",
    "        # Skip if already processed\n",
    "        if review_id in seen_review_ids:\n",
    "            continue\n",
    "            \n",
    "        seen_review_ids.add(review_id)\n",
    "        \n",
    "        try:\n",
    "            # Expand truncated review text (\"More\" button)\n",
    "            try:\n",
    "                more_button = r.find_element(By.CLASS_NAME, 'w8nwRe')\n",
    "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(0.15)\n",
    "            except (NoSuchElementException, StaleElementReferenceException):\n",
    "                pass\n",
    "\n",
    "            # Extract review data\n",
    "            author_name = r.find_element(By.CLASS_NAME, 'd4r55').text\n",
    "            \n",
    "            # Check if this is an owner response (no rating element)\n",
    "            rating_elements = r.find_elements(By.CLASS_NAME, 'kvMYJc')\n",
    "            if not rating_elements:\n",
    "                continue  # Skip owner responses\n",
    "            \n",
    "            rating_element = rating_elements[0]\n",
    "            rating_text = rating_element.get_attribute('aria-label')\n",
    "            star_rating = int(rating_text.split(' ')[0])\n",
    "            review_text = r.find_element(By.CLASS_NAME, 'wiI7pd').text.strip()\n",
    "\n",
    "            if not review_text:\n",
    "                no_text_rating_count += 1\n",
    "\n",
    "            try:\n",
    "                date_element = r.find_element(By.CLASS_NAME, 'rsqApe')\n",
    "                posting_date = date_element.text\n",
    "            except NoSuchElementException:\n",
    "                posting_date = \"Date not found\"\n",
    "\n",
    "            all_reviews_data.append({\n",
    "                \"outlet\": outlet_name,\n",
    "                \"author\": author_name,\n",
    "                \"rating\": star_rating,\n",
    "                \"text\": review_text,\n",
    "                \"date_posted\": posting_date\n",
    "            })\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # Scroll down smoothly - KEY FIX: Multiple small scrolls\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\n",
    "            \"arguments[0].scrollBy(0, arguments[0].scrollHeight / 3);\", \n",
    "            scrollable_div\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Additional wait for lazy loading\n",
    "    time.sleep(scroll_pause)\n",
    "    \n",
    "    new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "    \n",
    "    # If the scroll height hasn't changed AND we didn't find new reviews, increment the patience counter\n",
    "    if new_height == previous_height:\n",
    "        if not new_reviews:\n",
    "            no_new_count += 1\n",
    "        # If new_reviews *was* found but the height didn't change, we reset the patience counter\n",
    "        # because the page likely rendered hidden reviews without scrolling.\n",
    "    else:\n",
    "        no_new_count = 0 # Reset patience if scrolling was successful\n",
    "        \n",
    "    previous_height = new_height\n",
    "\n",
    "    # After your existing scroll logic, try scrolling back up occasionally\n",
    "    if scroll_iteration % 10 == 0:\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, -500);\", scrollable_div)\n",
    "        time.sleep(0.5)\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, 1000);\", scrollable_div)    \n",
    "\n",
    "# ==============================\n",
    "# SAVE RESULTS\n",
    "# ==============================\n",
    "driver.quit()\n",
    "\n",
    "if all_reviews_data:\n",
    "    os.makedirs(\"Reviews\", exist_ok=True)\n",
    "    output_filename = os.path.join(\"Reviews\", f\"{outlet_name}_reviews.csv\")\n",
    "    df_reviews = pd.DataFrame(all_reviews_data)\n",
    "    \n",
    "    # Remove duplicates based on author + text combination\n",
    "    initial_count = len(df_reviews)\n",
    "    df_reviews = df_reviews.drop_duplicates(subset=['author', 'text'], keep='first')\n",
    "    final_count = len(df_reviews)\n",
    "    \n",
    "    if initial_count > final_count:\n",
    "        print(f\"âš ï¸  Removed {initial_count - final_count} duplicate reviews\")\n",
    "    \n",
    "    df_reviews.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nâœ… Saved {final_count} unique reviews to '{output_filename}'\")\n",
    "    print(f\"ðŸ“„ Found {no_text_rating_count} reviews that were ratings only (no text).\")\n",
    "    print(f\"ðŸ“ˆ Review breakdown by rating:\")\n",
    "    print(df_reviews['rating'].value_counts().sort_index(ascending=False))\n",
    "else:\n",
    "    print(\"âŒ No reviews were scraped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48605924",
   "metadata": {},
   "source": [
    "### REVIEW EXTRACTION: BOTTOM 5 OUTLETS\n",
    "140. ---\n",
    "*141. Anytime Fitness Paya Lebar (3.7/5)- 139 Reviews, 75 Reviews\n",
    "*142. Anytime Fitness Upper Cross Street (3.5/5)- 142 Reviews, 89 Reviews\n",
    "*143. Anytime Fitness hillV2 (3.2/5)- 112 Reviews, 80 Reviews\n",
    "144. Anytime Fitness NEX (3.1/5)- 303 Reviews, 171 Reviews\n",
    "145. Anytime Fitness Northpoint City (3/5)- 242 Ratings, 157 Reviews\n",
    "\n",
    "*(<100 reviews after scraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f5632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Setting up WebDriver...\n",
      "âœ… Chrome WebDriver initialized successfully.\n",
      "\n",
      "ðŸš€ Found 5 outlets to scrape.\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Northpoint City ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJqTFUhpIV2jER8kd6GBxvZ0A\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 50)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 18: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 19: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 20: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 21: Found 20 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 22: Found 20 new reviews (Total: 200)\n",
      "ðŸ“Š Iteration 23: Found 20 new reviews (Total: 210)\n",
      "ðŸ“Š Iteration 24: Found 20 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 25: Found 20 new reviews (Total: 230)\n",
      "ðŸ“Š Iteration 26: Found 20 new reviews (Total: 240)\n",
      "ðŸ“Š Iteration 27: Found 20 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 28: Found 4 new reviews (Total: 244)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 157 unique reviews to 'Reviews/ Worst/Anytime Fitness Northpoint City_reviews.csv'\n",
      "ðŸ“„ Found 0 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness NEX ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJIV3T6qYX2jERA8evjvZnH64\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 18: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 19: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 20: Found 20 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 21: Found 20 new reviews (Total: 200)\n",
      "ðŸ“Š Iteration 22: Found 20 new reviews (Total: 210)\n",
      "ðŸ“Š Iteration 23: Found 20 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 24: Found 20 new reviews (Total: 230)\n",
      "ðŸ“Š Iteration 25: Found 20 new reviews (Total: 240)\n",
      "ðŸ“Š Iteration 26: Found 20 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 27: Found 20 new reviews (Total: 260)\n",
      "ðŸ“Š Iteration 28: Found 20 new reviews (Total: 270)\n",
      "ðŸ“Š Iteration 29: Found 20 new reviews (Total: 280)\n",
      "ðŸ“Š Iteration 30: Found 20 new reviews (Total: 290)\n",
      "ðŸ“Š Iteration 31: Found 20 new reviews (Total: 300)\n",
      "ðŸ“Š Iteration 32: Found 12 new reviews (Total: 302)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 171 unique reviews to 'Reviews/ Worst/Anytime Fitness NEX_reviews.csv'\n",
      "ðŸ“„ Found 0 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness hillV2 ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJH3LLm1IQ2jERgHlnHILVwYQ\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 40)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 15: Found 4 new reviews (Total: 114)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 80 unique reviews to 'Reviews/ Worst/Anytime Fitness hillV2_reviews.csv'\n",
      "ðŸ“„ Found 0 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Upper Cross Street ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJy0KJ3-8Z2jERhxE3MUKa7p4\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 17: Found 4 new reviews (Total: 144)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 89 unique reviews to 'Reviews/ Worst/Anytime Fitness Upper Cross Street_reviews.csv'\n",
      "ðŸ“„ Found 0 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Paya Lebar ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJUa4-4xYY2jERzTkowOfjaQI\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 15: Found 16 new reviews (Total: 146)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 75 unique reviews to 'Reviews/ Worst/Anytime Fitness Paya Lebar_reviews.csv'\n",
      "ðŸ“„ Found 0 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ All scraping complete. Driver closed. ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ==============================\n",
    "# --- 1. SETUP DRIVER (ONLY ONCE) ---\n",
    "# ==============================\n",
    "options = ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"--lang=en-US\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"--headless=new\")  # Recommended for stable batch processing\n",
    "\n",
    "print(\"âš™ï¸ Setting up WebDriver...\")\n",
    "try:\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=options\n",
    "    )\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    wait = WebDriverWait(driver, 20) # Increased wait time for robustness\n",
    "    actions = ActionChains(driver)\n",
    "    print(\"âœ… Chrome WebDriver initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to initialize WebDriver: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==============================\n",
    "# --- 2. SCRAPING FUNCTION ---\n",
    "# ==============================\n",
    "\n",
    "def scrape_reviews(outlet_name, outlet_url, driver, wait):\n",
    "    \"\"\"Navigates to the outlet, scrapes all reviews, and saves the data.\"\"\"\n",
    "    print(f\"\\n--- ðŸ§­ Starting scrape for: {outlet_name} ---\")\n",
    "    print(f\"ðŸ”— URL: {outlet_url}\")\n",
    "\n",
    "    all_reviews_data = []\n",
    "    seen_review_ids = set()\n",
    "    no_text_rating_count = 0\n",
    "    scroll_pause = 2.0\n",
    "    max_no_new = 8 # Increased patience\n",
    "    \n",
    "    try:\n",
    "        # OPEN OUTLET PAGE AND CLICK REVIEWS\n",
    "        driver.get(outlet_url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Click the \"Reviews\" button\n",
    "        reviews_button = wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label, \"Reviews for\")]'))\n",
    "        )\n",
    "        reviews_button.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # SCROLL AND SCRAPE REVIEWS\n",
    "        scrollable_div = wait.until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]'))\n",
    "        )\n",
    "\n",
    "        no_new_count = 0\n",
    "        previous_height = 0\n",
    "        scroll_iteration = 0\n",
    "\n",
    "        print(\"ðŸ”„ Starting to scroll and collect reviews...\")\n",
    "        \n",
    "        while True:\n",
    "            scroll_iteration += 1\n",
    "            \n",
    "            # Find all reviews currently loaded\n",
    "            review_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "            new_reviews = [r for r in review_elements if r.get_attribute(\"data-review-id\") not in seen_review_ids]\n",
    "\n",
    "            if new_reviews:\n",
    "                no_new_count = 0\n",
    "                print(f\"ðŸ“Š Iteration {scroll_iteration}: Found {len(new_reviews)} new reviews (Total: {len(seen_review_ids) + len(new_reviews)})\")\n",
    "            else:\n",
    "                no_new_count += 1\n",
    "                print(f\"â³ No new reviews found. Waiting... ({no_new_count}/{max_no_new})\")\n",
    "                if no_new_count >= max_no_new:\n",
    "                    print(\"âœ‹ Reached end of reviews.\")\n",
    "                    break\n",
    "                    \n",
    "            # Process new reviews\n",
    "            for r in new_reviews:\n",
    "                review_id = r.get_attribute(\"data-review-id\")\n",
    "                \n",
    "                if review_id in seen_review_ids:\n",
    "                    continue\n",
    "                    \n",
    "                seen_review_ids.add(review_id)\n",
    "                \n",
    "                try:\n",
    "                    # Expand truncated review text (\"More\" button)\n",
    "                    try:\n",
    "                        more_button = r.find_element(By.CLASS_NAME, 'w8nwRe')\n",
    "                        driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                        time.sleep(0.15)\n",
    "                    except (NoSuchElementException, StaleElementReferenceException):\n",
    "                        pass\n",
    "\n",
    "                    # Extract data and skip owner response\n",
    "                    author_name = r.find_element(By.CLASS_NAME, 'd4r55').text\n",
    "                    rating_elements = r.find_elements(By.CLASS_NAME, 'kvMYJc')\n",
    "                    if not rating_elements:\n",
    "                        continue \n",
    "                    \n",
    "                    rating_element = rating_elements[0]\n",
    "                    rating_text = rating_element.get_attribute('aria-label')\n",
    "                    star_rating = int(rating_text.split(' ')[0])\n",
    "\n",
    "                    # Robust extraction of review text:\n",
    "                    # - use find_elements to avoid NoSuchElementException when the text node is absent\n",
    "                    # - normalize text by coercing None -> '' and stripping whitespace\n",
    "                    text_elems = r.find_elements(By.CLASS_NAME, 'wiI7pd')\n",
    "                    if text_elems:\n",
    "                        review_text = (text_elems[0].text or '').strip()\n",
    "                    else:\n",
    "                        review_text = ''\n",
    "\n",
    "                    if review_text == '':\n",
    "                        no_text_rating_count += 1\n",
    "\n",
    "                    try:\n",
    "                        date_element = r.find_element(By.CLASS_NAME, 'rsqApe')\n",
    "                        posting_date = date_element.text\n",
    "                    except NoSuchElementException:\n",
    "                        posting_date = \"Date not found\"\n",
    "\n",
    "                    all_reviews_data.append({\n",
    "                        \"outlet\": outlet_name,\n",
    "                        \"author\": author_name,\n",
    "                        \"rating\": star_rating,\n",
    "                        \"text\": review_text,\n",
    "                        \"date_posted\": posting_date\n",
    "                    })\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            # Scroll down the large jump for loading\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollBy(0, 5000);\", \n",
    "                scrollable_div\n",
    "            )\n",
    "            time.sleep(scroll_pause)\n",
    "\n",
    "            # Check for scroll height change\n",
    "            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "            if new_height == previous_height:\n",
    "                if not new_reviews:\n",
    "                    no_new_count += 1\n",
    "            else:\n",
    "                no_new_count = 0\n",
    "                \n",
    "            previous_height = new_height\n",
    "\n",
    "            # Back-scroll occasionally for stability\n",
    "            if scroll_iteration % 10 == 0 and scroll_iteration > 0:\n",
    "                driver.execute_script(\"arguments[0].scrollBy(0, -200);\", scrollable_div) \n",
    "                time.sleep(0.5)\n",
    "                driver.execute_script(\"arguments[0].scrollBy(0, 400);\", scrollable_div)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸš¨ An error occurred while scraping {outlet_name}: {e}\")\n",
    "    \n",
    "    # --- SAVE RESULTS ---\n",
    "    if all_reviews_data:\n",
    "        os.makedirs(\"Reviews/ Worst\", exist_ok=True)\n",
    "        # Clean the name for a safe filename\n",
    "        safe_outlet_name = \"\".join(c for c in outlet_name if c.isalnum() or c in (' ', '_')).rstrip()\n",
    "        output_filename = os.path.join(\"Reviews/ Worst\", f\"{safe_outlet_name}_reviews.csv\")\n",
    "        df_reviews = pd.DataFrame(all_reviews_data)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        initial_count = len(df_reviews)\n",
    "        df_reviews = df_reviews.drop_duplicates(subset=['author', 'text'], keep='first')\n",
    "        final_count = len(df_reviews)\n",
    "        \n",
    "        if initial_count > final_count:\n",
    "            print(f\"âš ï¸  Removed {initial_count - final_count} duplicate reviews\")\n",
    "        \n",
    "        df_reviews.to_csv(output_filename, index=False)\n",
    "        print(f\"âœ… Saved {final_count} unique reviews to '{output_filename}'\")\n",
    "        print(f\"ðŸ“„ Found {no_text_rating_count} reviews that were ratings only (no text).\")\n",
    "        # print(df_reviews['rating'].value_counts().sort_index(ascending=False))\n",
    "    else:\n",
    "        print(f\"âŒ No reviews were scraped for {outlet_name}.\")\n",
    "\n",
    "# ==============================\n",
    "# --- 3. MAIN EXECUTION LOOP ---\n",
    "# ==============================\n",
    "\n",
    "df_outlets = pd.read_csv(\"bottom_5_outlets.csv\")\n",
    "print(f\"\\nðŸš€ Found {len(df_outlets)} outlets to scrape.\")\n",
    "\n",
    "# Iterate over each row (each outlet) in the DataFrame\n",
    "for index, row in df_outlets.iterrows():\n",
    "    outlet_name = row[\"name\"]\n",
    "    outlet_url = row[\"maps_url\"]\n",
    "    \n",
    "    # Call the scraping function for the current outlet\n",
    "    scrape_reviews(outlet_name, outlet_url, driver, wait)\n",
    "\n",
    "# Clean up and close the browser after the loop finishes\n",
    "driver.quit()\n",
    "print(\"\\n--- ðŸ All scraping complete. Driver closed. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee245f",
   "metadata": {},
   "source": [
    "## RE-SCRAPE BOTTOM 20 OUTLETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7a1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Setting up WebDriver...\n",
      "âœ… Chrome WebDriver initialized successfully.\n",
      "DEBUG: loading bottom_20_outlets from: /Users/breann/Documents/GitHub/IS434-Anytime-Fitness/Google-Reviews/Outlets/bottom_20_outlets.csv exists? True\n",
      "\n",
      "ðŸš€ Found 20 outlets to scrape.\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Northpoint City ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJqTFUhpIV2jER8kd6GBxvZ0A\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 18: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 19: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 20: Found 20 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 21: Found 20 new reviews (Total: 200)\n",
      "ðŸ“Š Iteration 22: Found 20 new reviews (Total: 210)\n",
      "ðŸ“Š Iteration 23: Found 20 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 24: Found 20 new reviews (Total: 230)\n",
      "ðŸ“Š Iteration 25: Found 20 new reviews (Total: 240)\n",
      "ðŸ“Š Iteration 26: Found 20 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 27: Found 8 new reviews (Total: 248)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 244 unique reviews to 'Reviews/ Worst/Anytime Fitness Northpoint City_reviews.csv'\n",
      "ðŸ“„ Found 85 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness NEX ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJIV3T6qYX2jERA8evjvZnH64\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 18: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 19: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 20: Found 20 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 21: Found 20 new reviews (Total: 200)\n",
      "ðŸ“Š Iteration 22: Found 20 new reviews (Total: 210)\n",
      "ðŸ“Š Iteration 23: Found 20 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 24: Found 20 new reviews (Total: 230)\n",
      "ðŸ“Š Iteration 25: Found 20 new reviews (Total: 240)\n",
      "ðŸ“Š Iteration 26: Found 20 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 27: Found 20 new reviews (Total: 260)\n",
      "ðŸ“Š Iteration 28: Found 20 new reviews (Total: 270)\n",
      "ðŸ“Š Iteration 29: Found 20 new reviews (Total: 280)\n",
      "ðŸ“Š Iteration 30: Found 20 new reviews (Total: 290)\n",
      "ðŸ“Š Iteration 31: Found 20 new reviews (Total: 300)\n",
      "ðŸ“Š Iteration 32: Found 12 new reviews (Total: 302)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âš ï¸  Removed 1 duplicate reviews\n",
      "âœ… Saved 295 unique reviews to 'Reviews/ Worst/Anytime Fitness NEX_reviews.csv'\n",
      "ðŸ“„ Found 125 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness hillV2 ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJH3LLm1IQ2jERgHlnHILVwYQ\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 40)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 15: Found 4 new reviews (Total: 114)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 112 unique reviews to 'Reviews/ Worst/Anytime Fitness hillV2_reviews.csv'\n",
      "ðŸ“„ Found 32 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Upper Cross Street ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJy0KJ3-8Z2jERhxE3MUKa7p4\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 17: Found 4 new reviews (Total: 144)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 142 unique reviews to 'Reviews/ Worst/Anytime Fitness Upper Cross Street_reviews.csv'\n",
      "ðŸ“„ Found 53 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Paya Lebar ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJUa4-4xYY2jERzTkowOfjaQI\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 15: Found 16 new reviews (Total: 146)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 138 unique reviews to 'Reviews/ Worst/Anytime Fitness Paya Lebar_reviews.csv'\n",
      "ðŸ“„ Found 63 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Kovan ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJk4DuSrQX2jEREXTna9XgYf0\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 12: Found 14 new reviews (Total: 114)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 107 unique reviews to 'Reviews/ Worst/Anytime Fitness Kovan_reviews.csv'\n",
      "ðŸ“„ Found 41 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Jurong East Central ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJM8FF1ZAR2jERuDhsvx_JALo\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 40)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 80)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 18: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 19: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 20: Found 20 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 21: Found 20 new reviews (Total: 200)\n",
      "ðŸ“Š Iteration 22: Found 20 new reviews (Total: 210)\n",
      "ðŸ“Š Iteration 23: Found 20 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 24: Found 20 new reviews (Total: 230)\n",
      "ðŸ“Š Iteration 25: Found 20 new reviews (Total: 240)\n",
      "ðŸ“Š Iteration 26: Found 20 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 27: Found 18 new reviews (Total: 258)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 249 unique reviews to 'Reviews/ Worst/Anytime Fitness Jurong East Central_reviews.csv'\n",
      "ðŸ“„ Found 45 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Cecil Street ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJqeYwSVUZ2jERtu1TapbIfB4\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 18: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 19: Found 2 new reviews (Total: 172)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 171 unique reviews to 'Reviews/ Worst/Anytime Fitness Cecil Street_reviews.csv'\n",
      "ðŸ“„ Found 35 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Clementi City ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJEaSloh8b2jERrZ8ril0BArE\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 50)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 170)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 160 unique reviews to 'Reviews/ Worst/Anytime Fitness Clementi City_reviews.csv'\n",
      "ðŸ“„ Found 47 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Choa Chu Kang Centre ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJgVqV6K0R2jERx19-94Knvow\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 16: Found 8 new reviews (Total: 138)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 134 unique reviews to 'Reviews/ Worst/Anytime Fitness Choa Chu Kang Centre_reviews.csv'\n",
      "ðŸ“„ Found 29 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Buangkok ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJrbVjGUEW2jERcka-oARsD2k\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 12: Found 2 new reviews (Total: 102)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 101 unique reviews to 'Reviews/ Worst/Anytime Fitness Buangkok_reviews.csv'\n",
      "ðŸ“„ Found 38 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Admiralty ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJU7LU3psT2jERRm-JGgZg4Tg\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 18: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 19: Found 20 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 20: Found 20 new reviews (Total: 200)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 190 unique reviews to 'Reviews/ Worst/Anytime Fitness Admiralty_reviews.csv'\n",
      "ðŸ“„ Found 56 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Bukit Timah ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJk-uNfYoQ2jER8xHHpU1P2v4\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 150)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 140 unique reviews to 'Reviews/ Worst/Anytime Fitness Bukit Timah_reviews.csv'\n",
      "ðŸ“„ Found 44 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Jalan Besar ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJq6pa2rcZ2jERPyIiRMpVMCM\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 16: Found 2 new reviews (Total: 132)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 131 unique reviews to 'Reviews/ Worst/Anytime Fitness Jalan Besar_reviews.csv'\n",
      "ðŸ“„ Found 52 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness West Coast Plaza ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJLXtnjpMa2jERBuUUK527K8c\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 130)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 120 unique reviews to 'Reviews/ Worst/Anytime Fitness West Coast Plaza_reviews.csv'\n",
      "ðŸ“„ Found 48 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJs-_B1-492jER30H1zKMHqBo\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 18: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 19: Found 20 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 20: Found 20 new reviews (Total: 200)\n",
      "ðŸ“Š Iteration 21: Found 20 new reviews (Total: 210)\n",
      "ðŸ“Š Iteration 22: Found 20 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 23: Found 20 new reviews (Total: 230)\n",
      "ðŸ“Š Iteration 24: Found 20 new reviews (Total: 240)\n",
      "ðŸ“Š Iteration 25: Found 20 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 26: Found 20 new reviews (Total: 260)\n",
      "ðŸ“Š Iteration 27: Found 20 new reviews (Total: 270)\n",
      "ðŸ“Š Iteration 28: Found 20 new reviews (Total: 280)\n",
      "ðŸ“Š Iteration 29: Found 20 new reviews (Total: 290)\n",
      "ðŸ“Š Iteration 30: Found 20 new reviews (Total: 300)\n",
      "ðŸ“Š Iteration 31: Found 20 new reviews (Total: 310)\n",
      "ðŸ“Š Iteration 32: Found 20 new reviews (Total: 320)\n",
      "ðŸ“Š Iteration 33: Found 20 new reviews (Total: 330)\n",
      "ðŸ“Š Iteration 34: Found 20 new reviews (Total: 340)\n",
      "ðŸ“Š Iteration 35: Found 20 new reviews (Total: 350)\n",
      "ðŸ“Š Iteration 36: Found 20 new reviews (Total: 360)\n",
      "ðŸ“Š Iteration 37: Found 20 new reviews (Total: 370)\n",
      "ðŸ“Š Iteration 38: Found 20 new reviews (Total: 380)\n",
      "ðŸ“Š Iteration 39: Found 20 new reviews (Total: 390)\n",
      "ðŸ“Š Iteration 40: Found 20 new reviews (Total: 400)\n",
      "ðŸ“Š Iteration 41: Found 20 new reviews (Total: 410)\n",
      "ðŸ“Š Iteration 42: Found 20 new reviews (Total: 420)\n",
      "ðŸ“Š Iteration 43: Found 20 new reviews (Total: 430)\n",
      "ðŸ“Š Iteration 44: Found 20 new reviews (Total: 440)\n",
      "ðŸ“Š Iteration 45: Found 20 new reviews (Total: 450)\n",
      "ðŸ“Š Iteration 46: Found 20 new reviews (Total: 460)\n",
      "ðŸ“Š Iteration 47: Found 20 new reviews (Total: 470)\n",
      "ðŸ“Š Iteration 48: Found 20 new reviews (Total: 480)\n",
      "ðŸ“Š Iteration 49: Found 20 new reviews (Total: 490)\n",
      "ðŸ“Š Iteration 50: Found 20 new reviews (Total: 500)\n",
      "ðŸ“Š Iteration 51: Found 20 new reviews (Total: 510)\n",
      "ðŸ“Š Iteration 52: Found 20 new reviews (Total: 520)\n",
      "ðŸ“Š Iteration 53: Found 20 new reviews (Total: 530)\n",
      "ðŸ“Š Iteration 54: Found 20 new reviews (Total: 540)\n",
      "ðŸ“Š Iteration 55: Found 20 new reviews (Total: 550)\n",
      "ðŸ“Š Iteration 56: Found 20 new reviews (Total: 560)\n",
      "ðŸ“Š Iteration 57: Found 20 new reviews (Total: 570)\n",
      "ðŸ“Š Iteration 58: Found 20 new reviews (Total: 580)\n",
      "ðŸ“Š Iteration 59: Found 20 new reviews (Total: 590)\n",
      "ðŸ“Š Iteration 60: Found 20 new reviews (Total: 600)\n",
      "ðŸ“Š Iteration 61: Found 20 new reviews (Total: 610)\n",
      "ðŸ“Š Iteration 62: Found 20 new reviews (Total: 620)\n",
      "ðŸ“Š Iteration 63: Found 20 new reviews (Total: 630)\n",
      "ðŸ“Š Iteration 64: Found 4 new reviews (Total: 624)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 622 unique reviews to 'Reviews/ Worst/Anytime Fitness_reviews.csv'\n",
      "ðŸ“„ Found 183 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Tiong Bahru Plaza ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJoyIDnVAZ2jERMrAUlT5qoWM\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 13: Found 2 new reviews (Total: 122)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 121 unique reviews to 'Reviews/ Worst/Anytime Fitness Tiong Bahru Plaza_reviews.csv'\n",
      "ðŸ“„ Found 63 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Tanjong Pagar ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJ5_qMmq8T2jERWkD2zBJt6Kk\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 30)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 40)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 50)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 60)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 70)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 80)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 90)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 100)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 19: Found 20 new reviews (Total: 110)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 21: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 22: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 23: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 24: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 25: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 26: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 27: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 28: Found 20 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 29: Found 20 new reviews (Total: 200)\n",
      "ðŸ“Š Iteration 30: Found 20 new reviews (Total: 210)\n",
      "ðŸ“Š Iteration 31: Found 20 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 32: Found 20 new reviews (Total: 230)\n",
      "ðŸ“Š Iteration 33: Found 20 new reviews (Total: 240)\n",
      "ðŸ“Š Iteration 34: Found 20 new reviews (Total: 250)\n",
      "ðŸ“Š Iteration 35: Found 20 new reviews (Total: 260)\n",
      "ðŸ“Š Iteration 36: Found 20 new reviews (Total: 270)\n",
      "ðŸ“Š Iteration 37: Found 14 new reviews (Total: 274)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 267 unique reviews to 'Reviews/ Worst/Anytime Fitness Tanjong Pagar_reviews.csv'\n",
      "ðŸ“„ Found 42 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness ACE The Place CC ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJMd4ygLsT2jER-rKdDfMJ4R4\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 40)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 50)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 18: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 19: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 20: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 21: Found 20 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 22: Found 20 new reviews (Total: 200)\n",
      "ðŸ“Š Iteration 23: Found 20 new reviews (Total: 210)\n",
      "ðŸ“Š Iteration 24: Found 20 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 25: Found 20 new reviews (Total: 230)\n",
      "ðŸ“Š Iteration 26: Found 20 new reviews (Total: 240)\n",
      "ðŸ“Š Iteration 27: Found 8 new reviews (Total: 238)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âš ï¸  Removed 1 duplicate reviews\n",
      "âœ… Saved 233 unique reviews to 'Reviews/ Worst/Anytime Fitness ACE The Place CC_reviews.csv'\n",
      "ðŸ“„ Found 76 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ§­ Starting scrape for: Anytime Fitness Bedok Central ---\n",
      "ðŸ”— URL: https://www.google.com/maps/place/?q=place_id:ChIJ2X09z0w92jERl_SgquDFLW8\n",
      "ðŸ”„ Starting to scroll and collect reviews...\n",
      "ðŸ“Š Iteration 1: Found 20 new reviews (Total: 20)\n",
      "ðŸ“Š Iteration 2: Found 20 new reviews (Total: 30)\n",
      "ðŸ“Š Iteration 3: Found 20 new reviews (Total: 40)\n",
      "ðŸ“Š Iteration 4: Found 20 new reviews (Total: 50)\n",
      "ðŸ“Š Iteration 5: Found 20 new reviews (Total: 60)\n",
      "ðŸ“Š Iteration 6: Found 20 new reviews (Total: 70)\n",
      "ðŸ“Š Iteration 7: Found 20 new reviews (Total: 80)\n",
      "ðŸ“Š Iteration 8: Found 20 new reviews (Total: 90)\n",
      "ðŸ“Š Iteration 9: Found 20 new reviews (Total: 100)\n",
      "ðŸ“Š Iteration 10: Found 20 new reviews (Total: 110)\n",
      "ðŸ“Š Iteration 11: Found 20 new reviews (Total: 120)\n",
      "ðŸ“Š Iteration 12: Found 20 new reviews (Total: 130)\n",
      "ðŸ“Š Iteration 13: Found 20 new reviews (Total: 140)\n",
      "ðŸ“Š Iteration 14: Found 20 new reviews (Total: 150)\n",
      "ðŸ“Š Iteration 15: Found 20 new reviews (Total: 160)\n",
      "ðŸ“Š Iteration 16: Found 20 new reviews (Total: 170)\n",
      "ðŸ“Š Iteration 17: Found 20 new reviews (Total: 180)\n",
      "ðŸ“Š Iteration 18: Found 20 new reviews (Total: 190)\n",
      "ðŸ“Š Iteration 19: Found 20 new reviews (Total: 200)\n",
      "ðŸ“Š Iteration 20: Found 20 new reviews (Total: 210)\n",
      "ðŸ“Š Iteration 21: Found 20 new reviews (Total: 220)\n",
      "ðŸ“Š Iteration 22: Found 12 new reviews (Total: 222)\n",
      "â³ No new reviews found. Waiting... (1/8)\n",
      "â³ No new reviews found. Waiting... (3/8)\n",
      "â³ No new reviews found. Waiting... (5/8)\n",
      "â³ No new reviews found. Waiting... (7/8)\n",
      "â³ No new reviews found. Waiting... (9/8)\n",
      "âœ‹ Reached end of reviews.\n",
      "âœ… Saved 216 unique reviews to 'Reviews/ Worst/Anytime Fitness Bedok Central_reviews.csv'\n",
      "ðŸ“„ Found 92 reviews that were ratings only (no text).\n",
      "\n",
      "--- ðŸ All scraping complete. Driver closed. ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ==============================\n",
    "# --- 1. SETUP DRIVER (ONLY ONCE) ---\n",
    "# ==============================\n",
    "options = ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"--lang=en-US\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"--headless=new\")  # Recommended for stable batch processing\n",
    "\n",
    "print(\"âš™ï¸ Setting up WebDriver...\")\n",
    "try:\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=options\n",
    "    )\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    wait = WebDriverWait(driver, 20) # Increased wait time for robustness\n",
    "    actions = ActionChains(driver)\n",
    "    print(\"âœ… Chrome WebDriver initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to initialize WebDriver: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==============================\n",
    "# --- 2. SCRAPING FUNCTION ---\n",
    "# ==============================\n",
    "\n",
    "def scrape_reviews(outlet_name, outlet_url, driver, wait):\n",
    "    \"\"\"Navigates to the outlet, scrapes all reviews, and saves the data.\"\"\"\n",
    "    print(f\"\\n--- ðŸ§­ Starting scrape for: {outlet_name} ---\")\n",
    "    print(f\"ðŸ”— URL: {outlet_url}\")\n",
    "\n",
    "    all_reviews_data = []\n",
    "    seen_review_ids = set()\n",
    "    no_text_rating_count = 0\n",
    "    scroll_pause = 2.0\n",
    "    max_no_new = 8 # Increased patience\n",
    "    \n",
    "    try:\n",
    "        # OPEN OUTLET PAGE AND CLICK REVIEWS\n",
    "        driver.get(outlet_url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Click the \"Reviews\" button\n",
    "        reviews_button = wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label, \"Reviews for\")]'))\n",
    "        )\n",
    "        reviews_button.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # SCROLL AND SCRAPE REVIEWS\n",
    "        scrollable_div = wait.until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]'))\n",
    "        )\n",
    "\n",
    "        no_new_count = 0\n",
    "        previous_height = 0\n",
    "        scroll_iteration = 0\n",
    "\n",
    "        print(\"ðŸ”„ Starting to scroll and collect reviews...\")\n",
    "        \n",
    "        while True:\n",
    "            scroll_iteration += 1\n",
    "            \n",
    "            # Find all reviews currently loaded\n",
    "            review_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "            new_reviews = [r for r in review_elements if r.get_attribute(\"data-review-id\") not in seen_review_ids]\n",
    "\n",
    "            if new_reviews:\n",
    "                no_new_count = 0\n",
    "                print(f\"ðŸ“Š Iteration {scroll_iteration}: Found {len(new_reviews)} new reviews (Total: {len(seen_review_ids) + len(new_reviews)})\")\n",
    "            else:\n",
    "                no_new_count += 1\n",
    "                print(f\"â³ No new reviews found. Waiting... ({no_new_count}/{max_no_new})\")\n",
    "                if no_new_count >= max_no_new:\n",
    "                    print(\"âœ‹ Reached end of reviews.\")\n",
    "                    break\n",
    "                    \n",
    "            # Process new reviews\n",
    "            for r in new_reviews:\n",
    "                review_id = r.get_attribute(\"data-review-id\")\n",
    "                \n",
    "                if review_id in seen_review_ids:\n",
    "                    continue\n",
    "                    \n",
    "                seen_review_ids.add(review_id)\n",
    "                \n",
    "                try:\n",
    "                    # Expand truncated review text (\"More\" button)\n",
    "                    try:\n",
    "                        more_button = r.find_element(By.CLASS_NAME, 'w8nwRe')\n",
    "                        driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                        time.sleep(0.15)\n",
    "                    except (NoSuchElementException, StaleElementReferenceException):\n",
    "                        pass\n",
    "\n",
    "                    # Extract data and skip owner response\n",
    "                    author_name = r.find_element(By.CLASS_NAME, 'd4r55').text\n",
    "                    rating_elements = r.find_elements(By.CLASS_NAME, 'kvMYJc')\n",
    "                    if not rating_elements:\n",
    "                        continue \n",
    "                    \n",
    "                    rating_element = rating_elements[0]\n",
    "                    rating_text = rating_element.get_attribute('aria-label')\n",
    "                    star_rating = int(rating_text.split(' ')[0])\n",
    "\n",
    "                    # Robust extraction of review text:\n",
    "                    # - use find_elements to avoid NoSuchElementException when the text node is absent\n",
    "                    # - normalize text by coercing None -> '' and stripping whitespace\n",
    "                    text_elems = r.find_elements(By.CLASS_NAME, 'wiI7pd')\n",
    "                    if text_elems:\n",
    "                        review_text = (text_elems[0].text or '').strip()\n",
    "                    else:\n",
    "                        review_text = ''\n",
    "\n",
    "                    if review_text == '':\n",
    "                        no_text_rating_count += 1\n",
    "\n",
    "                    try:\n",
    "                        date_element = r.find_element(By.CLASS_NAME, 'rsqApe')\n",
    "                        posting_date = date_element.text\n",
    "                    except NoSuchElementException:\n",
    "                        posting_date = \"Date not found\"\n",
    "\n",
    "                    all_reviews_data.append({\n",
    "                        \"outlet\": outlet_name,\n",
    "                        \"author\": author_name,\n",
    "                        \"rating\": star_rating,\n",
    "                        \"text\": review_text,\n",
    "                        \"date_posted\": posting_date\n",
    "                    })\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            # Scroll down the large jump for loading\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollBy(0, 5000);\", \n",
    "                scrollable_div\n",
    "            )\n",
    "            time.sleep(scroll_pause)\n",
    "\n",
    "            # Check for scroll height change\n",
    "            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "            if new_height == previous_height:\n",
    "                if not new_reviews:\n",
    "                    no_new_count += 1\n",
    "            else:\n",
    "                no_new_count = 0\n",
    "                \n",
    "            previous_height = new_height\n",
    "\n",
    "            # Back-scroll occasionally for stability\n",
    "            if scroll_iteration % 10 == 0 and scroll_iteration > 0:\n",
    "                driver.execute_script(\"arguments[0].scrollBy(0, -200);\", scrollable_div) \n",
    "                time.sleep(0.5)\n",
    "                driver.execute_script(\"arguments[0].scrollBy(0, 400);\", scrollable_div)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸš¨ An error occurred while scraping {outlet_name}: {e}\")\n",
    "    \n",
    "    # --- SAVE RESULTS ---\n",
    "    if all_reviews_data:\n",
    "        os.makedirs(\"Reviews/ Worst\", exist_ok=True)\n",
    "        # Clean the name for a safe filename\n",
    "        safe_outlet_name = \"\".join(c for c in outlet_name if c.isalnum() or c in (' ', '_')).rstrip()\n",
    "        output_filename = os.path.join(\"Reviews/ Worst\", f\"{safe_outlet_name}_reviews.csv\")\n",
    "        df_reviews = pd.DataFrame(all_reviews_data)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        initial_count = len(df_reviews)\n",
    "        df_reviews = df_reviews.drop_duplicates(subset=['author', 'text'], keep='first')\n",
    "        final_count = len(df_reviews)\n",
    "        \n",
    "        if initial_count > final_count:\n",
    "            print(f\"âš ï¸  Removed {initial_count - final_count} duplicate reviews\")\n",
    "        \n",
    "        df_reviews.to_csv(output_filename, index=False)\n",
    "        print(f\"âœ… Saved {final_count} unique reviews to '{output_filename}'\")\n",
    "        print(f\"ðŸ“„ Found {no_text_rating_count} reviews that were ratings only (no text).\")\n",
    "        # print(df_reviews['rating'].value_counts().sort_index(ascending=False))\n",
    "    else:\n",
    "        print(f\"âŒ No reviews were scraped for {outlet_name}.\")\n",
    "\n",
    "# ==============================\n",
    "# --- 3. MAIN EXECUTION LOOP ---\n",
    "# ==============================\n",
    "# changed code\n",
    "from pathlib import Path\n",
    "# use notebook CWD and resolve the repo layout reliably\n",
    "nb_cwd = Path.cwd().resolve()\n",
    "bottom_20_file = (nb_cwd / '..' / 'Outlets' / 'bottom_20_outlets.csv').resolve()\n",
    "# fallback to local Outlets if above doesn't exist\n",
    "if not bottom_20_file.exists():\n",
    "    bottom_20_file = (nb_cwd / 'Outlets' / 'bottom_20_outlets.csv').resolve()\n",
    "\n",
    "print(\"DEBUG: loading bottom_20_outlets from:\", bottom_20_file, \"exists?\", bottom_20_file.exists())\n",
    "df_outlets = pd.read_csv(str(bottom_20_file))\n",
    "# ...existing code...\n",
    "print(f\"\\nðŸš€ Found {len(df_outlets)} outlets to scrape.\")\n",
    "\n",
    "# Iterate over each row (each outlet) in the DataFrame\n",
    "for index, row in df_outlets.iterrows():\n",
    "    outlet_name = row[\"name\"]\n",
    "    outlet_url = row[\"maps_url\"]\n",
    "    \n",
    "    # Call the scraping function for the current outlet\n",
    "    scrape_reviews(outlet_name, outlet_url, driver, wait)\n",
    "\n",
    "# Clean up and close the browser after the loop finishes\n",
    "driver.quit()\n",
    "print(\"\\n--- ðŸ All scraping complete. Driver closed. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1057dfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb27f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is434_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
