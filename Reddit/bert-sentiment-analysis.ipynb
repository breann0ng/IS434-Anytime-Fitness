{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ba334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: torch in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/breann/anaconda3/envs/is434_env/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Install the core library for Transformers\n",
    "!pip install transformers\n",
    "\n",
    "# Install PyTorch or TensorFlow (the backend framework)\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "BASE_DIR = Path.cwd().parent \n",
    "REVIEWS_DIR = BASE_DIR / \"Reviews\" / \"All\"\n",
    "OVERVIEW_DIR = BASE_DIR / \"Reviews\" / \"Overview\"\n",
    "\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "TEXT_COLUMN = \"text\"\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Existing VADER summary for top 20\n",
    "VADER_FILE = OVERVIEW_DIR / \"top_20_outlets_with_sentiment.csv\"\n",
    "\n",
    "# Output CSV\n",
    "OUTPUT_FILE = OVERVIEW_DIR / \"top_20_outlets_with_BERT_sentiment.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Load top 20 outlets from VADER\n",
    "# -----------------------------\n",
    "vader_df = pd.read_csv(VADER_FILE)\n",
    "top20_outlets = vader_df['outlet'].tolist()\n",
    "top20_normalized = [x.strip().lower() for x in top20_outlets]\n",
    "print(f\"üìä Loaded {len(top20_outlets)} top 20 outlets from VADER summary\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Collect all review CSVs\n",
    "# -----------------------------\n",
    "csv_files = list(REVIEWS_DIR.glob(\"*.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"‚ùå No CSV files found in {REVIEWS_DIR}\")\n",
    "\n",
    "print(f\"üìÇ Found {len(csv_files)} outlet CSV files in '{REVIEWS_DIR}'\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Load BERT sentiment model\n",
    "# -----------------------------\n",
    "print(f\"‚öôÔ∏è Loading BERT model: {MODEL_NAME} ...\")\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=MODEL_NAME, tokenizer=MODEL_NAME)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Process each outlet\n",
    "# -----------------------------\n",
    "bert_summaries = []\n",
    "\n",
    "MAX_LENGTH = 512  # max tokens for Roberta models\n",
    "\n",
    "for csv_path in tqdm(csv_files, desc=\"Processing outlets\"):\n",
    "    outlet_name = csv_path.stem\n",
    "    outlet_name_clean = outlet_name.replace(\"_reviews\", \"\").strip().lower()\n",
    "\n",
    "    if outlet_name_clean not in top20_normalized:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if TEXT_COLUMN not in df.columns:\n",
    "            continue\n",
    "        df = df.dropna(subset=[TEXT_COLUMN])\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        texts = df[TEXT_COLUMN].astype(str).tolist()\n",
    "\n",
    "        # Truncate texts to MAX_LENGTH\n",
    "        texts_truncated = [t[:MAX_LENGTH*4] for t in texts]  # ~4 chars per token\n",
    "\n",
    "        # Run BERT sentiment\n",
    "        results = sentiment_pipeline(texts_truncated, batch_size=BATCH_SIZE)\n",
    "        df['bert_label'] = [r['label'] for r in results]\n",
    "        df['bert_score'] = [r['score'] for r in results]\n",
    "\n",
    "        # Normalize labels\n",
    "        label_map = {\n",
    "            'LABEL_0': 'negative',\n",
    "            'LABEL_1': 'neutral',\n",
    "            'LABEL_2': 'positive',\n",
    "            'NEGATIVE': 'negative',\n",
    "            'NEUTRAL': 'neutral',\n",
    "            'POSITIVE': 'positive'\n",
    "        }\n",
    "        df['bert_cat'] = df['bert_label'].map(label_map).fillna(df['bert_label'])\n",
    "\n",
    "        # Compute counts and percentages\n",
    "        total_reviews = len(df)\n",
    "        pos = df['bert_cat'].eq('positive').sum()\n",
    "        neu = df['bert_cat'].eq('neutral').sum()\n",
    "        neg = df['bert_cat'].eq('negative').sum()\n",
    "\n",
    "        bert_summary = {\n",
    "            \"outlet_name\": outlet_name_clean,\n",
    "            \"total_reviews_bert\": total_reviews,\n",
    "            \"positive_bert\": int(pos),\n",
    "            \"neutral_bert\": int(neu),\n",
    "            \"negative_bert\": int(neg),\n",
    "            \"pct_positive_bert\": round(pos / total_reviews * 100, 2),\n",
    "            \"pct_neutral_bert\": round(neu / total_reviews * 100, 2),\n",
    "            \"pct_negative_bert\": round(neg / total_reviews * 100, 2)\n",
    "        }\n",
    "        bert_summaries.append(bert_summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {outlet_name}: {e}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: Merge with VADER summary\n",
    "# -----------------------------\n",
    "bert_df = pd.DataFrame(bert_summaries)\n",
    "if bert_df.empty:\n",
    "    raise ValueError(\"‚ùå No BERT results were generated.\")\n",
    "\n",
    "# Ensure consistent column for merge\n",
    "vader_df['outlet_clean'] = vader_df['outlet'].str.strip().str.lower()\n",
    "merged_df = pd.merge(\n",
    "    vader_df,\n",
    "    bert_df,\n",
    "    left_on='outlet_clean',\n",
    "    right_on='outlet_name',\n",
    "    how='left'\n",
    ").drop(columns=['outlet_clean', 'outlet_name'])\n",
    "\n",
    "# -----------------------------\n",
    "# Step 6: Save final CSV\n",
    "# -----------------------------\n",
    "merged_df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"‚úÖ Saved BERT-augmented bottom 20 outlets CSV: {OUTPUT_FILE}\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\nSample rows:\")\n",
    "print(merged_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is434_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
