{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lab 4 (Part 1) - PRAW Search Function\n",
    "\n",
    "In this lab, you will attempt to \"search\" posts based on one or more keywords.\n",
    "\n",
    "Ref: https://www.reddit.com/dev/api/#GET_search\n",
    "https://praw.readthedocs.io/en/latest/code_overview/models/subreddit.html#praw.models.Subreddit.search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have you already installed praw package in Anaconda? Please check.\n",
    "import praw\n",
    "from datetime import datetime\n",
    "\n",
    "# The information for following fileds are obtained from Reddit\n",
    "# You should have created a Reddit app and gotten these values.\n",
    "# We firstly create a reddit object bound to variable `reddit`\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id = \"CoEHlOZSnws8fscZPMNE0Q\", # See slide 9 & 10 of Lab 2 Guide\n",
    "    client_secret = \"eAkexuMuchegtDk59ZH_HlA6Gkc2jg\", # See slide 9 & 10 of Lab 2 Guide\n",
    "   username = \"Emotional_Ad_1570\", # See slide 4 (step 3) of Lab 2 Guide\n",
    "   password = \"Iloveis434!\",  # See slide 4 (step 3) of Lab 2 Guide\n",
    "   user_agent = \"IS434_Project\" # See slide 9 & 10 of Lab 2 Guide\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RELEVANT REDDIT POSTS\n",
    "subreddits = ['singapore', 'SingaporeFitness', 'askSingapore']\n",
    "search_keyword = 'Anytime Fitness'\n",
    "posts_data = []\n",
    "\n",
    "for subreddit_name in subreddits:\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    for submission in subreddit.search(search_keyword, sort='relevance', time_filter='all', limit=None):\n",
    "        downvotes = submission.score - submission.upvote_ratio * submission.score\n",
    "        posts_data.append({\n",
    "            'ID': submission.id,\n",
    "            'Subreddit': subreddit_name,\n",
    "            'Author': str(submission.author),\n",
    "            'Created_UTC': datetime.fromtimestamp(int(submission.created_utc)),\n",
    "            'Title': submission.title,\n",
    "            'Content': submission.selftext,\n",
    "            'Upvotes': submission.score,  # Reddit API does not provide explicit upvotes\n",
    "            'Downvotes': int(downvotes), # Estimated based on upvote ratio\n",
    "            'Num_Comments': submission.num_comments,\n",
    "            'Link': f\"https://www.reddit.com{submission.permalink}\"\n",
    "        })\n",
    "\n",
    "# Convert list of dicts to DataFrame\n",
    "df = pd.DataFrame(posts_data)\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('reddit_singapore_anytimefitness_posts.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3322 rows to reddit_singapore_anytimefitness_comments.xlsx\n"
     ]
    }
   ],
   "source": [
    "# AFTER CLEANING AND KEEPING RELEVANT POSTS, GET THE COMMENTS OF THESE POSTS\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the cleaned list of relevant post IDs from your edited post file\n",
    "posts_df = pd.read_excel('reddit_singapore_anytimefitness_posts.xlsx')\n",
    "relevant_ids = set(posts_df['ID'].astype(str))  # ensure match by string type\n",
    "\n",
    "rows = []\n",
    "\n",
    "subreddits = ['singapore', 'SingaporeFitness', 'askSingapore']\n",
    "\n",
    "for subreddit_name in subreddits:\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    # Fetch ALL posts (could optimize w/ search, but this ensures full coverage)\n",
    "    for submission in subreddit.search('Anytime Fitness', sort='relevance', time_filter='all', limit=None):\n",
    "        if submission.id not in relevant_ids:\n",
    "            continue  # skip non-relevant posts\n",
    "\n",
    "        post_fields = {\n",
    "            'ID': submission.id,\n",
    "            'Subreddit': subreddit_name,\n",
    "            'Author': str(submission.author),\n",
    "            'Created_UTC': datetime.fromtimestamp(int(submission.created_utc)),\n",
    "            'Title': submission.title,\n",
    "            'Content': submission.selftext,\n",
    "            'Upvotes': submission.score,\n",
    "            'Downvotes': int(submission.score - submission.upvote_ratio * submission.score) if submission.upvote_ratio is not None else None,\n",
    "            'Num_Comments': submission.num_comments,\n",
    "            'Link': f\"https://www.reddit.com{submission.permalink}\"\n",
    "        }\n",
    "\n",
    "        # Fetch and flatten all comments\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        flat_comments = submission.comments.list()\n",
    "        for idx, comment in enumerate(flat_comments, 1):\n",
    "            row = post_fields.copy()\n",
    "            row['comment_number'] = idx\n",
    "            row['comment'] = comment.body\n",
    "            row['comment_upvotes'] = comment.score\n",
    "            row['comment_downvotes'] = None  # Not available from Reddit API\n",
    "            rows.append(row)\n",
    "\n",
    "# Convert to DataFrame and save to Excel\n",
    "columns = [\n",
    "    'ID','Subreddit','Author','Created_UTC','Title','Content','Upvotes','Downvotes',\n",
    "    'Num_Comments','Link','comment_number','comment','comment_upvotes','comment_downvotes'\n",
    "]\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df.to_excel('reddit_singapore_anytimefitness_comments.xlsx', index=False)\n",
    "print(f\"Saved {len(df)} rows to reddit_singapore_anytimefitness_comments.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment columns added and Excel overwritten in place.\n"
     ]
    }
   ],
   "source": [
    "# GET SENTIMENT SCORE OF COMMENTS\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load your existing Excel file\n",
    "excel_filename = 'reddit_singapore_anytimefitness_comments.xlsx'\n",
    "df = pd.read_excel(excel_filename)\n",
    "\n",
    "# Initialize Sentiment Intensity Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to analyze each comment for sentiment\n",
    "def analyze_comment_sentiment(comment):\n",
    "    sentiment = analyzer.polarity_scores(str(comment))\n",
    "    compound = sentiment[\"compound\"]\n",
    "    if compound >= 0.05:\n",
    "        label = \"Positive\"\n",
    "    elif compound <= -0.05:\n",
    "        label = \"Negative\"\n",
    "    else:\n",
    "        label = \"Neutral\"\n",
    "    return pd.Series([compound, label])\n",
    "\n",
    "# Apply sentiment analysis, add columns 'comment_compound_score' and 'comment_sentiment_label'\n",
    "df[['comment_compound_score', 'comment_sentiment_label']] = df['comment'].apply(analyze_comment_sentiment)\n",
    "\n",
    "# Save the updated DataFrame back to the same Excel file (overwrite)\n",
    "df.to_excel(excel_filename, index=False)\n",
    "\n",
    "print(\"Sentiment columns added and Excel overwritten in place.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
